[
  
  {
    "question": "Create a new Git branch and switch to it.",
    "answer": "1. git branch <branch_name>\n2. git checkout <branch_name>"
  },
  {
    "question": "Compress the folder reports into reports.tar.gz.",
    "answer": "1. tar -czvf reports.tar.gz reports"
  },
  {
    "question": "List all Python files in the current directory recursively.",
    "answer": "1. find . -name '*.py'"
  },
  {
    "question": "Set up a virtual environment and install requests.",
    "answer": "1. python3 -m venv env\n2. source env/bin/activate\n3. pip install requests"
  },
  {
    "question": "Fetch only the first ten lines of a file named output.log.",
    "answer": "1. head -n 10 output.log"
  },
  {
    "question": "How to check the size of a directory including all its contents?",
    "answer": "1. du -sh <directory_name>"
  },
  {
    "question": "How to find and delete all .tmp files in the current directory and its subdirectories?",
    "answer": "1. find . -name '*.tmp' -type f -delete"
  },
  {
    "question": "How do I get the directory where a Bash script is located from within the script itself?",
    "answer": "#!/usr/bin/env bash\n\nSCRIPT_DIR=$( cd -- \"$( dirname -- \"${BASH_SOURCE[0]}\" )\" &> /dev/null && pwd )\n\nis a useful one-liner which will give you the full directory name of the script no matter where it is being called from.\nIt will work as long as the last component of the path used to find the script is not a symlink (directory links are OK).  If you also want to resolve any links to the script itself, you need a multi-line solution:\n#!/usr/bin/env bash\n\nget_script_dir()\n{\n    local SOURCE_PATH=\"${BASH_SOURCE[0]}\"\n    local SYMLINK_DIR\n    local SCRIPT_DIR\n    # Resolve symlinks recursively\n    while [ -L \"$SOURCE_PATH\" ]; do\n        # Get symlink directory\n        SYMLINK_DIR=\"$( cd -P \"$( dirname \"$SOURCE_PATH\" )\" >/dev/null 2>&1 && pwd )\"\n        # Resolve symlink target (relative or absolute)\n        SOURCE_PATH=\"$(readlink \"$SOURCE_PATH\")\"\n        # Check if candidate path is relative or absolute\n        if [[ $SOURCE_PATH != /* ]]; then\n            # Candidate path is relative, resolve to full path\n            SOURCE_PATH=$SYMLINK_DIR/$SOURCE_PATH\n        fi\n    done\n    # Get final script directory path from fully resolved source path\n    SCRIPT_DIR=\"$(cd -P \"$( dirname \"$SOURCE_PATH\" )\" >/dev/null 2>&1 && pwd)\"\n    echo \"$SCRIPT_DIR\"\n}\n\necho \"get_script_dir: $(get_script_dir)\"\n\nThis last one will work with any combination of aliases, source, bash -c, symlinks, etc.\nBeware: if you cd to a different directory before running this snippet, the result may be incorrect!\nAlso, watch out for $CDPATH gotchas, and stderr output side effects if the user has smartly overridden cd to redirect output to stderr instead (including escape sequences, such as when calling update_terminal_cwd >&2 on Mac). Adding >/dev/null 2>&1 at the end of your cd command will take care of both possibilities.\nTo understand how it works, try running this more verbose form:\n#!/usr/bin/env bash\n\nSOURCE=${BASH_SOURCE[0]}\nwhile [ -L \"$SOURCE\" ]; do # resolve $SOURCE until the file is no longer a symlink\n  TARGET=$(readlink \"$SOURCE\")\n  if [[ $TARGET == /* ]]; then\n    echo \"SOURCE '$SOURCE' is an absolute symlink to '$TARGET'\"\n    SOURCE=$TARGET\n  else\n    DIR=$( dirname \"$SOURCE\" )\n    echo \"SOURCE '$SOURCE' is a relative symlink to '$TARGET' (relative to '$DIR')\"\n    SOURCE=$DIR/$TARGET # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located\n  fi\ndone\necho \"SOURCE is '$SOURCE'\"\nRDIR=$( dirname \"$SOURCE\" )\nDIR=$( cd -P \"$( dirname \"$SOURCE\" )\" >/dev/null 2>&1 && pwd )\nif [ \"$DIR\" != \"$RDIR\" ]; then\n  echo \"DIR '$RDIR' resolves to '$DIR'\"\nfi\necho \"DIR is '$DIR'\"\n\nAnd it will print something like:\nSOURCE './scriptdir.sh' is a relative symlink to 'sym2/scriptdir.sh' (relative to '.')\nSOURCE is './sym2/scriptdir.sh'\nDIR './sym2' resolves to '/home/ubuntu/dotfiles/fo fo/real/real1/real2'\nDIR is '/home/ubuntu/dotfiles/fo fo/real/real1/real2'"
  },
  {
    "question": "How do I check if a directory exists or not in a Bash shell script?",
    "answer": "To check if a directory exists:\nif [ -d \"$DIRECTORY\" ]; then\n  echo \"$DIRECTORY does exist.\"\nfi\n\nTo check if a directory does not exist:\nif [ ! -d \"$DIRECTORY\" ]; then\n  echo \"$DIRECTORY does not exist.\"\nfi\n\n\nHowever, as Jon Ericson points out, subsequent commands may not work as intended if you do not take into account that a symbolic link to a directory will also pass this check.\nE.g. running this:\nln -s \"$ACTUAL_DIR\" \"$SYMLINK\"\nif [ -d \"$SYMLINK\" ]; then \n  rmdir \"$SYMLINK\" \nfi\n\nWill produce the error message:\nrmdir: failed to remove `symlink': Not a directory\n\nSo symbolic links may have to be treated differently, if subsequent commands expect directories:\nif [ -d \"$LINK_OR_DIR\" ]; then \n  if [ -L \"$LINK_OR_DIR\" ]; then\n    # It is a symlink!\n    # Symbolic link specific commands go here.\n    rm \"$LINK_OR_DIR\"\n  else\n    # It's a directory!\n    # Directory command goes here.\n    rmdir \"$LINK_OR_DIR\"\n  fi\nfi\n\n\nTake particular note of the double-quotes used to wrap the variables. The reason for this is explained by 8jean in another answer.\nIf the variables contain spaces or other unusual characters it will probably cause the script to fail."
  },
  {
    "question": "How do I tell if a file does not exist in Bash?",
    "answer": "The test command (written as [ here) has a \"not\" logical operator, ! (exclamation mark):\nif [ ! -f /tmp/foo.txt ]; then\n    echo \"File not found!\"\nfi"
  },
  {
    "question": "Echo newline in Bash prints literal \\n",
    "answer": "Use printf instead:\nprintf \"hello\\nworld\\n\"\n\nprintf behaves more consistently across different environments than echo."
  },
  {
    "question": "How to check if a string contains a substring in Bash",
    "answer": "You can use Marcus's answer (* wildcards) outside a case statement, too, if you use double brackets:\n\nstring='My long string'\nif [[ $string == *\"My long\"* ]]; then\n  echo \"It's there!\"\nfi\n\n\nNote that spaces in the needle string need to be placed between double quotes, and the * wildcards should be outside. Also note that a simple comparison operator is used (i.e. ==), not the regex operator =~."
  },
  {
    "question": "How to concatenate string variables in Bash",
    "answer": "foo=\"Hello\"\nfoo=\"${foo} World\"\necho \"${foo}\"\n> Hello World\n\n\nIn general to concatenate two variables you can just write them one after another:\n\na='Hello'\nb='World'\nc=\"${a} ${b}\"\necho \"${c}\"\n> Hello World"
  },
  {
    "question": "What does &quot; 2&gt;&amp;1 &quot; mean?",
    "answer": "File descriptor 1 is the standard output (stdout).\nFile descriptor 2 is the standard error (stderr).\nAt first, 2>1 may look like a good way to redirect stderr to stdout. However, it will actually be interpreted as \"redirect stderr to a file named 1\".\n& indicates that what follows and precedes is a file descriptor, and not a filename. Thus, we use 2>&1. Consider >& to be a redirect merger operator."
  },
  {
    "question": "How can I check if a program exists from a Bash script?",
    "answer": "Answer\nPOSIX compatible:\ncommand -v <the_command>\n\nExample use:\nif ! command -v <the_command> >/dev/null 2>&1\nthen\n    echo \"<the_command> could not be found\"\n    exit 1\nfi\n\nFor Bash specific environments:\nhash <the_command> # For regular commands. Or...\ntype <the_command> # To check built-ins and keywords\n\nExplanation\nAvoid which. Not only is it an external process you're launching for doing very little (meaning builtins like hash, type or command are way cheaper), you can also rely on the builtins to actually do what you want, while the effects of external commands can easily vary from system to system.\nWhy care?\n\nMany operating systems have a which that doesn't even set an exit status, meaning the if which foo won't even work there and will always report that foo exists, even if it doesn't (note that some POSIX shells appear to do this for hash too).\nMany operating systems make which do custom and evil stuff like change the output or even hook into the package manager.\n\nSo, don't use which. Instead use one of these:\ncommand -v foo >/dev/null 2>&1 || { echo >&2 \"I require foo but it's not installed.  Aborting.\"; exit 1; }\n\ntype foo >/dev/null 2>&1 || { echo >&2 \"I require foo but it's not installed.  Aborting.\"; exit 1; }\n\nhash foo 2>/dev/null || { echo >&2 \"I require foo but it's not installed.  Aborting.\"; exit 1; }\n\n(Minor side-note: some will suggest 2>&- is the same 2>/dev/null but shorter – this is untrue.  2>&- closes FD 2 which causes an error in the program when it tries to write to stderr, which is very different from successfully writing to it and discarding the output (and dangerous!))\n(Additional minor side-note: some will suggest &>/dev/null, but this is not POSIX compliant)\nIf your hash bang is /bin/sh then you should care about what POSIX says. type and hash's exit codes aren't terribly well defined by POSIX, and hash is seen to exit successfully when the command doesn't exist (haven't seen this with type yet).  command's exit status is well defined by POSIX, so that one is probably the safest to use.\nIf your script uses bash though, POSIX rules don't really matter anymore and both type and hash become perfectly safe to use. type now has a -P to search just the PATH and hash has the side-effect that the command's location will be hashed (for faster lookup next time you use it), which is usually a good thing since you probably check for its existence in order to actually use it.\nAs a simple example, here's a function that runs gdate if it exists, otherwise date:\ngnudate() {\n    if hash gdate 2>/dev/null; then\n        gdate \"$@\"\n    else\n        date \"$@\"\n    fi\n}"
  },
  {
    "question": "How do I split a string on a delimiter in Bash?",
    "answer": "You can set the internal field separator (IFS) variable, and then let it parse into an array. When this happens in a command, then the assignment to IFS only takes place to that single command's environment (to read ). It then parses the input according to the IFS variable value into an array, which we can then iterate over.\nThis example will parse one line of items separated by ;, pushing it into an array:\nIFS=';' read -ra ADDR <<< \"$IN\"\nfor i in \"${ADDR[@]}\"; do\n  # process \"$i\"\ndone\n\nThis other example is for processing the whole content of $IN, each time one line of input separated by ;:\nwhile IFS=';' read -ra ADDR; do\n  for i in \"${ADDR[@]}\"; do\n    # process \"$i\"\n  done\ndone <<< \"$IN\""
  },
  {
    "question": "Extract filename and extension in Bash",
    "answer": "First, get file name without the path:\nfilename=$(basename -- \"$fullfile\")\nextension=\"${filename##*.}\"\nfilename=\"${filename%.*}\"\n\nAlternatively, you can focus on the last '/' of the path instead of the '.' which should work even if you have unpredictable file extensions:\nfilename=\"${fullfile##*/}\"\n\nYou may want to check the documentation :\n\nOn the web at section \"3.5.3 Shell Parameter Expansion\"\nIn the bash manpage at section called \"Parameter Expansion\""
  },
  {
    "question": "How to change the output color of echo in Linux",
    "answer": "You can use these ANSI escape codes:\nBlack        0;30     Dark Gray     1;30\nRed          0;31     Light Red     1;31\nGreen        0;32     Light Green   1;32\nBrown/Orange 0;33     Yellow        1;33\nBlue         0;34     Light Blue    1;34\nPurple       0;35     Light Purple  1;35\nCyan         0;36     Light Cyan    1;36\nLight Gray   0;37     White         1;37\n\nAnd then use them like this in your script:\n#    .---------- constant part!\n#    vvvv vvvv-- the code from above\nRED='\\033[0;31m'\nNC='\\033[0m' # No Color\nprintf \"I ${RED}love${NC} Stack Overflow\\n\"\n\nwhich prints love in red.\nFrom @james-lim's comment, if you are using the echo command, be sure to use the -e flag to allow backslash escapes.\n#    .---------- constant part!\n#    vvvv vvvv-- the code from above\nRED='\\033[0;31m'\nNC='\\033[0m' # No Color\necho -e \"I ${RED}love${NC} Stack Overflow\"\n\nNote: Don't add \"\\n\" when using echo unless you want to add an additional empty line."
  },
  {
    "question": "How do I parse command line arguments in Bash?",
    "answer": "Bash Space-Separated (e.g., --option argument)\n\ncat >/tmp/demo-space-separated.sh <<'EOF'\n#!/bin/bash\n\nPOSITIONAL_ARGS=()\n\nwhile [[ $# -gt 0 ]]; do\n  case $1 in\n    -e|--extension)\n      EXTENSION=\"$2\"\n      shift # past argument\n      shift # past value\n      ;;\n    -s|--searchpath)\n      SEARCHPATH=\"$2\"\n      shift # past argument\n      shift # past value\n      ;;\n    --default)\n      DEFAULT=YES\n      shift # past argument\n      ;;\n    -*|--*)\n      echo \"Unknown option $1\"\n      exit 1\n      ;;\n    *)\n      POSITIONAL_ARGS+=(\"$1\") # save positional arg\n      shift # past argument\n      ;;\n  esac\ndone\n\nset -- \"${POSITIONAL_ARGS[@]}\" # restore positional parameters\n\necho \"FILE EXTENSION  = ${EXTENSION}\"\necho \"SEARCH PATH     = ${SEARCHPATH}\"\necho \"DEFAULT         = ${DEFAULT}\"\necho \"Number files in SEARCH PATH with EXTENSION:\" $(ls -1 \"${SEARCHPATH}\"/*.\"${EXTENSION}\" | wc -l)\n\nif [[ -n $1 ]]; then\n    echo \"Last line of file specified as non-opt/last argument:\"\n    tail -1 \"$1\"\nfi\nEOF\n\nchmod +x /tmp/demo-space-separated.sh\n\n/tmp/demo-space-separated.sh -e conf -s /etc /etc/hosts\n\nOutput from copy-pasting the block above\nFILE EXTENSION  = conf\nSEARCH PATH     = /etc\nDEFAULT         =\nNumber files in SEARCH PATH with EXTENSION: 14\nLast line of file specified as non-opt/last argument:\n#93.184.216.34    example.com\n\nUsage\ndemo-space-separated.sh -e conf -s /etc /etc/hosts\n\n\nBash Equals-Separated (e.g., --option=argument)\ncat >/tmp/demo-equals-separated.sh <<'EOF'\n#!/bin/bash\n\nfor i in \"$@\"; do\n  case $i in\n    -e=*|--extension=*)\n      EXTENSION=\"${i#*=}\"\n      shift # past argument=value\n      ;;\n    -s=*|--searchpath=*)\n      SEARCHPATH=\"${i#*=}\"\n      shift # past argument=value\n      ;;\n    --default)\n      DEFAULT=YES\n      shift # past argument with no value\n      ;;\n    -*|--*)\n      echo \"Unknown option $i\"\n      exit 1\n      ;;\n    *)\n      ;;\n  esac\ndone\n\necho \"FILE EXTENSION  = ${EXTENSION}\"\necho \"SEARCH PATH     = ${SEARCHPATH}\"\necho \"DEFAULT         = ${DEFAULT}\"\necho \"Number files in SEARCH PATH with EXTENSION:\" $(ls -1 \"${SEARCHPATH}\"/*.\"${EXTENSION}\" | wc -l)\n\nif [[ -n $1 ]]; then\n    echo \"Last line of file specified as non-opt/last argument:\"\n    tail -1 $1\nfi\nEOF\n\nchmod +x /tmp/demo-equals-separated.sh\n\n/tmp/demo-equals-separated.sh -e=conf -s=/etc /etc/hosts\n\nOutput from copy-pasting the block above\nFILE EXTENSION  = conf\nSEARCH PATH     = /etc\nDEFAULT         =\nNumber files in SEARCH PATH with EXTENSION: 14\nLast line of file specified as non-opt/last argument:\n#93.184.216.34    example.com\n\nUsage\ndemo-equals-separated.sh -e=conf -s=/etc /etc/hosts\n\n\nTo better understand ${i#*=} search for \"Substring Removal\" in this guide. It is functionally equivalent to `sed 's/[^=]*=//' <<< \"$i\"` which calls a needless subprocess or `echo \"$i\" | sed 's/[^=]*=//'` which calls two needless subprocesses.\n\nUsing bash with getopt[s]\ngetopt(1) limitations (older, relatively-recent getopt versions):\n\ncan't handle arguments that are empty strings\ncan't handle arguments with embedded whitespace\n\nMore recent getopt versions don't have these limitations. For more information, see these docs.\n\nPOSIX getopts\nAdditionally, the POSIX shell and others offer getopts which doen't have these limitations. I've included a simplistic getopts example.\ncat >/tmp/demo-getopts.sh <<'EOF'\n#!/bin/sh\n\n# A POSIX variable\nOPTIND=1         # Reset in case getopts has been used previously in the shell.\n\n# Initialize our own variables:\noutput_file=\"\"\nverbose=0\n\nwhile getopts \"h?vf:\" opt; do\n  case \"$opt\" in\n    h|\\?)\n      show_help\n      exit 0\n      ;;\n    v)  verbose=1\n      ;;\n    f)  output_file=$OPTARG\n      ;;\n  esac\ndone\n\nshift $((OPTIND-1))\n\n[ \"${1:-}\" = \"--\" ] && shift\n\necho \"verbose=$verbose, output_file='$output_file', Leftovers: $@\"\nEOF\n\nchmod +x /tmp/demo-getopts.sh\n\n/tmp/demo-getopts.sh -vf /etc/hosts foo bar\n\nOutput from copy-pasting the block above\nverbose=1, output_file='/etc/hosts', Leftovers: foo bar\n\nUsage\ndemo-getopts.sh -vf /etc/hosts foo bar\n\nThe advantages of getopts are:\n\nIt's more portable, and will work in other shells like dash.\nIt can handle multiple single options like -vf filename in the typical Unix way, automatically.\n\nThe disadvantage of getopts is that it can only handle short options (-h, not --help) without additional code.\nThere is a getopts tutorial which explains what all of the syntax and variables mean.  In bash, there is also help getopts, which might be informative."
  },
  {
    "question": "How do I set a variable to the output of a command in Bash?",
    "answer": "In addition to backticks `command`, command substitution can be done with $(command) or \"$(command)\", which I find easier to read, and allows for nesting.\nOUTPUT=\"$(ls -1)\"\necho \"${OUTPUT}\"\n\nMULTILINE=\"$(ls \\\n   -1)\"\necho \"${MULTILINE}\"\n\nQuoting (\") does matter to preserve multi-line variable values and it is safer to use with whitespace and special characters such as (*) and therefore advised; it is, however, optional on the right-hand side of an assignment when word splitting is not performed, so OUTPUT=$(ls -1) would work fine."
  },
  {
    "question": "How to check if a variable is set in Bash",
    "answer": "(Usually) The right way\nif [ -z ${var+x} ]; then echo \"var is unset\"; else echo \"var is set to '$var'\"; fi\n\nwhere ${var+x} is a parameter expansion which evaluates to nothing if var is unset, and substitutes the string x otherwise.\nQuotes Digression\nQuotes can be omitted (so we can say ${var+x} instead of \"${var+x}\") because this syntax & usage guarantees this will only expand to something that does not require quotes (since it either expands to x (which contains no word breaks so it needs no quotes), or to nothing (which results in [ -z  ], which conveniently evaluates to the same value (true) that [ -z \"\" ] does as well)).\nHowever, while quotes can be safely omitted, and it was not immediately obvious to all (it wasn't even apparent to the first author of this quotes explanation who is also a major Bash coder), it would sometimes be better to write the solution with quotes as [ -z \"${var+x}\" ], at the very small possible cost of an O(1) speed penalty.  The first author also added this as a comment next to the code using this solution giving the URL to this answer, which now also includes the explanation for why the quotes can be safely omitted.\n(Often) The wrong way\nif [ -z \"$var\" ]; then echo \"var is blank\"; else echo \"var is set to '$var'\"; fi\n\nThis is often wrong because it doesn't distinguish between a variable that is unset and a variable that is set to the empty string. That is to say, if var='', then the above solution will output \"var is blank\".\nThe distinction between unset and \"set to the empty string\" is essential in situations where the user has to specify an extension, or additional list of properties, and that not specifying them defaults to a non-empty value, whereas specifying the empty string should make the script use an empty extension or list of additional properties.\nThe distinction may not be essential in every scenario though. In those cases  [ -z \"$var\" ] will be just fine."
  },
  {
    "question": "Loop through an array of strings in Bash?",
    "answer": "You can use it like this:\n\n## declare an array variable\ndeclare -a arr=(\"element1\" \"element2\" \"element3\")\n\n## now loop through the above array\nfor i in \"${arr[@]}\"\ndo\n   echo \"$i\"\n   # or do whatever with individual element of the array\ndone\n\n# You can access them using echo \"${arr[0]}\", \"${arr[1]}\" also\n\n\nAlso works for multi-line array declaration\n\ndeclare -a arr=(\"element1\" \n                \"element2\" \"element3\"\n                \"element4\"\n                )"
  },
  {
    "question": "How to reload .bashrc settings without logging out and back in again?",
    "answer": "You can enter the long form command:\nsource ~/.bashrc\n\nor you can use the shorter version of the command:\n. ~/.bashrc"
  },
  {
    "question": "How do I iterate over a range of numbers defined by variables in Bash?",
    "answer": "for i in $(seq 1 $END); do echo $i; done\n\nedit: I prefer seq over the other methods because I can actually remember it ;)"
  },
  {
    "question": "Looping through the content of a file in Bash",
    "answer": "One way to do it is:\n\nwhile read p; do\n  echo \"$p\"\ndone <peptides.txt\n\n\nAs pointed out in the comments, this has the side effects of trimming leading whitespace, interpreting backslash sequences, and skipping the last line if it's missing a terminating linefeed. If these are concerns, you can do:\n\nwhile IFS=\"\" read -r p || [ -n \"$p\" ]\ndo\n  printf '%s\\n' \"$p\"\ndone < peptides.txt\n\n\n\n\nExceptionally, if the loop body may read from standard input, you can open the file using a different file descriptor:\n\nwhile read -u 10 p; do\n  ...\ndone 10<peptides.txt\n\n\nHere, 10 is just an arbitrary number (different from 0, 1, 2)."
  },
  {
    "question": "How can I count all the lines of code in a directory recursively?",
    "answer": "Try:\nfind . -name '*.php' | xargs wc -l\n\nor (when file names include special characters such as spaces)\nfind . -name '*.php' | sed 's/.*/\"&\"/' | xargs  wc -l\n\nThe SLOCCount tool may help as well.\nIt will give an accurate source lines of code count for whatever\nhierarchy you point it at, as well as some additional stats.\nSorted output:\nfind . -name '*.php' | xargs wc -l | sort -nr"
  },
  {
    "question": "How to redirect and append both standard output and standard error to a file with Bash",
    "answer": "cmd >>file.txt 2>&1\n\n\nBash executes the redirects from left to right as follows:\n\n\n>>file.txt: Open file.txt in append mode and redirect stdout there.\n2>&1: Redirect stderr to \"where stdout is currently going\". In this case, that is a file opened in append mode. In other words, the &1 reuses the file descriptor which stdout currently uses."
  },
  {
    "question": "Check existence of input argument in a Bash shell script",
    "answer": "It is:\nif [ $# -eq 0 ]\n  then\n    echo \"No arguments supplied\"\nfi\n\nThe $# variable will tell you the number of input arguments the script was passed.\nOr you can check if an argument is an empty string or not like:\nif [ -z \"$1\" ]\n  then\n    echo \"No argument supplied\"\nfi\n\nThe -z switch will test if the expansion of \"$1\" is a null string or not. If it is a null string then the body is executed."
  },
  {
    "question": "How do I prompt for Yes/No/Cancel input in a Linux shell script?",
    "answer": "A widely available method to get user input at a shell prompt is the read command. Here is a demonstration:\nwhile true; do\n    read -p \"Do you wish to install this program? \" yn\n    case $yn in\n        [Yy]* ) make install; break;;\n        [Nn]* ) exit;;\n        * ) echo \"Please answer yes or no.\";;\n    esac\ndone\n\n\nAnother method, pointed out by Steven Huwig, is Bash's select command. Here is the same example using select:\necho \"Do you wish to install this program?\"\nselect yn in \"Yes\" \"No\"; do\n    case $yn in\n        Yes ) make install; break;;\n        No ) exit;;\n    esac\ndone\n\nWith select you don't need to sanitize the input – it displays the available choices, and you type a number corresponding to your choice. It also loops automatically, so there's no need for a while true loop to retry if they give invalid input. If you want to allow more flexible input (accepting the words of the options, rather than just their number), you can alter it like this:\necho \"Do you wish to install this program?\"\nselect strictreply in \"Yes\" \"No\"; do\n    relaxedreply=${strictreply:-$REPLY}\n    case $relaxedreply in\n        Yes | yes | y ) make install; break;;\n        No  | no  | n ) exit;;\n    esac\ndone\n\n\nAlso, Léa Gris demonstrated a way to make the request language agnostic in her answer. Adapting my first example to better serve multiple languages might look like this:\nset -- $(locale LC_MESSAGES)\nyesexpr=\"$1\"; noexpr=\"$2\"; yesword=\"$3\"; noword=\"$4\"\n\nwhile true; do\n    read -p \"Install (${yesword} / ${noword})? \" yn\n    if [[ \"$yn\" =~ $yesexpr ]]; then make install; exit; fi\n    if [[ \"$yn\" =~ $noexpr ]]; then exit; fi\n    echo \"Answer ${yesword} / ${noword}.\"\ndone\n\nObviously other communication strings remain untranslated here (Install, Answer) which would need to be addressed in a more fully completed translation, but even a partial translation would be helpful in many cases.\n\nFinally, please check out the excellent answer by F. Hauri."
  },
  {
    "question": "Difference between sh and Bash",
    "answer": "What is sh?\nsh (or the Shell Command Language) is a programming language described by the POSIX standard. It has many implementations (ksh88, Dash, ...). Bash can also be considered an implementation of sh (see below).\nBecause sh is a specification, not an implementation, /bin/sh is a symlink (or a hard link) to an actual implementation on most POSIX systems.\nWhat is Bash?\nBash started as an sh-compatible implementation (although it predates the POSIX standard by a few years), but as time passed it has acquired many extensions. Many of these extensions may change the behavior of valid POSIX shell scripts, so by itself Bash is not a valid POSIX shell. Rather, it is a dialect of the POSIX shell language.\nBash supports a --posix switch, which makes it more POSIX-compliant. It also tries to mimic POSIX if invoked as sh.\nsh = bash?\nFor a long time, /bin/sh used to point to /bin/bash on most GNU/Linux systems. As a result, it had almost become safe to ignore the difference between the two. But that started to change recently.\nSome popular examples of systems where /bin/sh does not point to /bin/bash (and on some of which /bin/bash may not even exist) are:\n\nModern Debian and Ubuntu systems, which symlink sh to dash by default;\nBusybox, which is usually run during the Linux system boot time as part of initramfs. It uses the ash shell implementation.\nBSD systems, and in general any non-Linux systems. OpenBSD uses pdksh, a descendant of the KornShell. FreeBSD's sh is a descendant of the original Unix Bourne shell.  Solaris has its own sh which for a long time was not POSIX-compliant; a free implementation is available from the Heirloom project.\n\nHow can you find out what /bin/sh points to on your system?\nThe complication is that /bin/sh could be a symbolic link or a hard link. If it's a symbolic link, a portable way to resolve it is:\n% file -h /bin/sh\n/bin/sh: symbolic link to bash\n\nIf it's a hard link, try\n% find -L /bin -samefile /bin/sh\n/bin/sh\n/bin/bash\n\nIn fact, the -L flag covers both symlinks and hardlinks,\nbut the disadvantage of this method is that it is not portable —\nPOSIX does not require find to support the -samefile option, although both GNU find and FreeBSD find support it.\nShebang line\nUltimately, it's up to you to decide which one to use, by writing the «shebang» line as the very first line of the script.\nE.g.\n#!/bin/sh\n\nwill use sh (and whatever that happens to point to),\n#!/bin/bash\n\nwill use /bin/bash if it's available (and fail with an error message if it's not). Of course, you can also specify another implementation, e.g.\n#!/bin/dash\n\nWhich one to use\nFor my own scripts, I prefer sh for the following reasons:\n\nit is standardized\nit is much simpler and easier to learn\nit is portable across POSIX systems — even if they happen not to have bash, they are required to have sh\n\nThere are advantages to using bash as well. Its features make programming more convenient and similar to programming in other modern programming languages. These include things like scoped local variables and arrays. Plain sh is a very minimalistic programming language."
  },
  {
    "question": "How to specify the private SSH-key to use when executing shell command on Git?",
    "answer": "None of these solutions worked for me.\nInstead, I elaborate on @Martin v. Löwis  's mention of setting a config file for SSH.\nSSH will look for the user's ~/.ssh/config file. I have mine setup as:\nHost gitserv\n    Hostname remote.server.com\n    IdentityFile ~/.ssh/id_rsa.github\n    IdentitiesOnly yes # see NOTES below\n    AddKeysToAgent yes\n\nAnd I add a remote git repository:\ngit remote add origin git@gitserv:myrepo.git\n\n(or clone a fresh copy of the repo with git@gitserv:myrepo.git as address)\nAnd then git commands work normally for me.\ngit push -v origin master\n\nIf you have submodules, you can also execute the following in the repo directory, to force the submodules to use the same key:\ngit config url.git@gitserv:.insteadOf https://remote.server.com\n\nNOTES\n\nThe IdentitiesOnly yes is required to prevent the SSH default behavior of sending the identity file matching the default filename for each protocol. If you have a file named ~/.ssh/id_rsa that will get tried BEFORE your ~/.ssh/id_rsa.github without this option.\n\nAddKeysToAgent yes lets you avoid reentering the key passphrase every time.\n\nYou can also add User git to avoid writing git@ every time.\n\n\nReferences\n\nBest way to use multiple SSH private keys on one client\nHow could I stop ssh offering a wrong key"
  },
  {
    "question": "Make a Bash alias that takes a parameter?",
    "answer": "Bash alias does not directly accept parameters. You will have to create a function.\n\nalias does not accept parameters but a function can be called just like an alias. For example:\n\nmyfunction() {\n    #do things with parameters like $1 such as\n    mv \"$1\" \"$1.bak\"\n    cp \"$2\" \"$1\"\n}\n\n\nmyfunction old.conf new.conf #calls `myfunction`\n\n\nBy the way, Bash functions defined in your .bashrc and other files are available as commands within your shell. So for instance you can call the earlier function like this \n\n$ myfunction original.conf my.conf"
  },
  {
    "question": "How to convert a string to lower case in Bash",
    "answer": "There are various ways:\nPOSIX standard\ntr\n$ echo \"$a\" | tr '[:upper:]' '[:lower:]'\nhi all\n\nAWK\n$ echo \"$a\" | awk '{print tolower($0)}'\nhi all\n\nNon-POSIX\nYou may run into portability issues with the following examples:\nBash 4.0\n$ echo \"${a,,}\"\nhi all\n\nsed\n$ echo \"$a\" | sed -e 's/\\(.*\\)/\\L\\1/'\nhi all\n# this also works:\n$ sed -e 's/\\(.*\\)/\\L\\1/' <<< \"$a\"\nhi all\n\nPerl\n$ echo \"$a\" | perl -ne 'print lc'\nhi all\n\nBash\nlc(){\n    case \"$1\" in\n        [A-Z])\n        n=$(printf \"%d\" \"'$1\")\n        n=$((n+32))\n        printf \\\\$(printf \"%o\" \"$n\")\n        ;;\n        *)\n        printf \"%s\" \"$1\"\n        ;;\n    esac\n}\nword=\"I Love Bash\"\nfor((i=0;i<${#word};i++))\ndo\n    ch=\"${word:$i:1}\"\n    lc \"$ch\"\ndone\n\nNote: YMMV on this one. Doesn't work for me (GNU bash version 4.2.46 and 4.0.33 (and same behaviour 2.05b.0 but nocasematch  is not implemented)) even with using shopt -u nocasematch;. Unsetting that nocasematch causes [[ \"fooBaR\" == \"FOObar\" ]] to match OK BUT inside case weirdly [b-z] are incorrectly matched by [A-Z]. Bash is confused by the double-negative (\"unsetting nocasematch\")! :-)"
  },
  {
    "question": "What is the preferred Bash shebang (&quot;#!&quot;)?",
    "answer": "You should use #!/usr/bin/env bash for portability: Different *nixes put bash in different places, and using /usr/bin/env is a workaround to run the first bash found on the PATH.\nAnd sh is not bash."
  },
  {
    "question": "echo that outputs to stderr",
    "answer": "You could do this, which facilitates reading:\n>&2 echo \"error\"\n\n>&2 copies file descriptor #2 to file descriptor #1. Therefore, after this redirection is performed, both file descriptors will refer to the same file: the one file descriptor #2 was originally referring to. For more information see the Bash Hackers Illustrated Redirection Tutorial."
  },
  {
    "question": "How to redirect output to a file and stdout",
    "answer": "The command you want is named tee:\n\nfoo | tee output.file\n\n\nFor example, if you only care about stdout:\n\nls -a | tee output.file\n\n\nIf you want to include stderr, do:\n\nprogram [arguments...] 2>&1 | tee outfile\n\n\n2>&1 redirects channel 2 (stderr/standard error) into channel 1 (stdout/standard output), such that both is written as stdout. It is also directed to the given output file as of the tee command.\n\nFurthermore, if you want to append to the log file, use tee -a as:\n\nprogram [arguments...] 2>&1 | tee -a outfile"
  },
  {
    "question": "YYYY-MM-DD format date in shell script",
    "answer": "In bash (>=4.2) it is preferable to use printf's built-in date formatter (part of bash) rather than the external date (usually GNU date). Note that invoking a subshell has performance problems in Cygwin due to a slow fork() call on Windows.\nAs such:\n# put current date as yyyy-mm-dd in $date\n# -1 -> explicit current date, bash >=4.3 defaults to current time if not provided\n# -2 -> start time for shell\nprintf -v date '%(%Y-%m-%d)T\\n' -1\n\n# put current date as yyyy-mm-dd HH:MM:SS in $date\nprintf -v date '%(%Y-%m-%d %H:%M:%S)T\\n' -1\n\n# to print directly remove -v flag, as such:\nprintf '%(%Y-%m-%d)T\\n' -1\n# -> current date printed to terminal\n\nIn bash (<4.2):\n# put current date as yyyy-mm-dd in $date\ndate=$(date '+%Y-%m-%d')\n\n# put current date as yyyy-mm-dd HH:MM:SS in $date\ndate=$(date '+%Y-%m-%d %H:%M:%S')\n\n# print current date directly\necho $(date '+%Y-%m-%d')\n\nOther available date formats can be viewed from the date man pages (for external non-bash specific command):\nman date"
  },
  {
    "question": "How do I undo the most recent local commits in Git?",
    "answer": "Undo a commit & redo\n$ git commit -m \"Something terribly misguided\" # (0: Your Accident)\n$ git reset HEAD~                              # (1)\n# === If you just want to undo the commit, stop here! ===\n[ edit files as necessary ]                    # (2)\n$ git add .                                    # (3)\n$ git commit -c ORIG_HEAD                      # (4)\n\n\ngit reset is the command responsible for the undo. It will undo your last commit while leaving your working tree (the state of your files on disk) untouched. You'll need to add them again before you can commit them again.\nMake corrections to working tree files.\ngit add anything that you want to include in your new commit.\nCommit the changes, reusing the old commit message. reset copied the old head to .git/ORIG_HEAD; commit with -c ORIG_HEAD will open an editor, which initially contains the log message from the old commit and allows you to edit it. If you do not need to edit the message, you could use the -C option.\n\nAlternatively, to edit the previous commit (or just its commit message), commit --amend will add changes within the current index to the previous commit.\nTo remove (not revert) a commit that has been pushed to the server, rewriting history with git push origin main --force[-with-lease] is necessary. It's almost always a bad idea to use --force; prefer --force-with-lease instead, and as noted in the git manual:\n\nYou should understand the implications of rewriting history if you amend a commit that has already been published.\n\n\nFurther Reading\nYou can use git reflog to determine the SHA-1 for the commit to which you wish to revert. Once you have this value, use the sequence of commands as explained above.\n\nHEAD~ is the same as HEAD~1. The article What is the HEAD in git? is helpful if you want to uncommit multiple commits."
  },
  {
    "question": "How do I delete a Git branch locally and remotely?",
    "answer": "Executive Summary\ngit push -d <remote_name> <branchname>   # Delete remote\ngit branch -d <branchname>               # Delete local\n\nNote: In most cases, <remote_name> will be origin.\nDelete Local Branch\nTo delete the local branch, use one of the following:\ngit branch -d <branch_name>\ngit branch -D <branch_name>\n\n\nThe -d option is an alias for --delete, which only deletes the branch if it has already been fully merged in its upstream branch.\nThe -D option is an alias for --delete --force, which deletes the branch \"irrespective of its merged status.\" [Source: man git-branch]\nAs of Git v2.3, git branch -d (delete) learned to honor the -f (force) flag.\nYou will receive an error if you try to delete the currently selected branch.\n\nDelete Remote Branch\nAs of Git v1.7.0, you can delete a remote branch using\n$ git push <remote_name> --delete <branch_name>\n\nwhich might be easier to remember than\n$ git push <remote_name> :<branch_name>\n\nwhich was added in Git v1.5.0 \"to delete a remote branch or a tag.\"\nStarting with Git v2.8.0, you can also use git push with the -d option as an alias for --delete. Therefore, the version of Git you have installed will dictate whether you need to use the easier or harder syntax.\nDelete Remote Branch [Original Answer from 5-Jan-2010]\nFrom Chapter 3 of Pro Git by Scott Chacon:\n\nDeleting Remote Branches\nSuppose you’re done with a remote branch — say, you and your collaborators are finished with a feature and have merged it into your remote’s main branch (or whatever branch your stable code-line is in). You can delete a remote branch using the rather obtuse syntax git push [remotename] :[branch]. If you want to delete your serverfix branch from the server, you run the following:\n$ git push origin :serverfix\nTo git@github.com:schacon/simplegit.git\n - [deleted]         serverfix\n\nBoom. No more branches on your server. You may want to dog-ear this page, because you’ll need that command, and you’ll likely forget the syntax. A way to remember this command is by recalling the git push [remotename] [localbranch]:[remotebranch] syntax that we went over a bit earlier. If you leave off the [localbranch] portion, then you’re basically saying, “Take nothing on my side and make it be [remotebranch].”\n\nI ran git push origin :bugfix, and it worked beautifully. Scott Chacon was right—I will want to dog-ear that page (or virtually dog ear-by answering this on Stack Overflow).\nFetch changes\nFinally, execute the following on other machines to propagate changes:\n# Fetch changes from all remotes and locally delete \n# remote deleted branches/tags etc\n# --prune will do the job :-;\ngit fetch --all --prune"
  },
  {
    "question": "What is the difference between &#39;git pull&#39; and &#39;git fetch&#39;?",
    "answer": "In the simplest terms, git pull does a git fetch followed by a git merge.\n\ngit fetch updates your remote-tracking branches under refs/remotes/<remote>/. This operation is safe to run at any time since it never changes any of your local branches under refs/heads.\ngit pull brings a local branch up-to-date with its remote version, while also updating your other remote-tracking branches.\nFrom the Git documentation for git pull:\n\ngit pull runs git fetch with the given parameters and then depending on configuration options or command line flags, will call either git rebase or git merge to reconcile diverging branches."
  },
  {
    "question": "How can I rename a local Git branch?",
    "answer": "To rename the current branch:\ngit branch -m <newname>\n\nTo rename a branch while pointed to any branch:\ngit branch -m <oldname> <newname>\n\n-m is short for --move.\n\nTo push the  local branch and reset the upstream branch:\ngit push origin -u <newname>\n\nTo delete the  remote branch:\ngit push origin --delete <oldname>\n\n\nTo create a git rename alias:\ngit config --global alias.rename 'branch -m'\n\n\nOn Windows or another case-insensitive filesystem, use -M if there are only capitalization changes in the name. Otherwise, Git will throw a \"branch already exists\" error.\ngit branch -M <newname>"
  },
  {
    "question": "How do I undo &#39;git add&#39; before commit?",
    "answer": "To unstage a specific file\ngit reset <file>\n\nThat will remove the file from the current index (the \"about to be committed\" list) without changing anything else.\nTo unstage all files from the current change set:\ngit reset\n\n\nIn old versions of Git, the above commands are equivalent to git reset HEAD <file> and git reset HEAD respectively, and will fail if HEAD is undefined (because you haven't yet made any commits in your repository) or ambiguous (because you created a branch called HEAD, which is a stupid thing that you shouldn't do). This was changed in Git 1.8.2, though, so in modern versions of Git you can use the commands above even prior to making your first commit:\n\n\"git reset\" (without options or parameters) used to error out when\nyou do not have any commits in your history, but it now gives you\nan empty index (to match non-existent commit you are not even on).\n\nDocumentation: git reset"
  },
  {
    "question": "How do I force &quot;git pull&quot; to overwrite local files?",
    "answer": "⚠ Warning:\nAny uncommitted local change to tracked files will be lost, even if staged.\nBut any local file that's not tracked by Git will not be affected.\n\n\nFirst, update all origin/<branch> refs to latest:\ngit fetch --all\n\nBackup your current branch (e.g. main):\ngit branch backup-main\n\nJump to the latest commit on origin/main and checkout those files:\ngit reset --hard origin/main\n\nExplanation:\ngit fetch downloads the latest from remote without trying to merge or rebase anything.\ngit reset resets the master branch to what you just fetched. The --hard option changes all the files in your working tree to match the files in origin/main.\n\nMaintain current local commits\n[*]: It's worth noting that it is possible to maintain current local commits by creating a branch from main before resetting:\ngit checkout main\ngit branch new-branch-to-save-current-commits\ngit fetch --all\ngit reset --hard origin/main\n\nAfter this, all of the old commits will be kept in new-branch-to-save-current-commits.\nUncommitted changes\nUncommitted changes, even if staged (with git add), will be lost. Make sure to stash or commit anything you need. For example, run the following:\ngit stash\n\nAnd later (after git reset), reapply these uncommitted changes:\ngit stash pop\n\n\nWhich may create merge conflicts."
  },
  {
    "question": "How to check out a remote Git branch?",
    "answer": "The answer has been split depending on whether there is one remote repository configured or multiple. The reason for this is that for the single remote case, some of the commands can be simplified as there is less ambiguity.\nUpdated for Git 2.23: For older versions, see the section at the end.\nWith One Remote\nIn both cases, start by fetching from the remote repository to make sure you have all the latest changes downloaded.\n$ git fetch\n\nThis will fetch all of the remote branches for you. You can see the branches available for checkout with:\n$ git branch -v -a\n\n...\nremotes/origin/test\n\nThe branches that start with remotes/* can be thought of as read only copies of the remote branches. To work on a branch you need to create a local branch from it. This is done with the Git command switch (since Git 2.23) by giving it the name of the remote branch (minus the remote name):\n$ git switch test\n\nIn this case Git is guessing (can be disabled with --no-guess) that you are trying to checkout and track the remote branch with the same name.\nWith Multiple Remotes\nIn the case where multiple remote repositories exist, the remote repository needs to be explicitly named.\nAs before, start by fetching the latest remote changes:\n$ git fetch origin\n\nThis will fetch all of the remote branches for you. You can see the branches available for checkout with:\n$ git branch -v -a\n\nWith the remote branches in hand, you now need to check out the branch you are interested in with -c to create a new local branch:\n$ git switch -c test origin/test\n\nFor more information about using git switch:\n$ man git-switch\n\nPrior to Git 2.23\ngit switch was added in Git 2.23, prior to this git checkout was used to switch branches.\nTo checkout out with only a single remote repository:\ngit checkout test\n\nif there are multiple remote repositories configured then it becomes a bit longer\ngit checkout -b test <name of remote>/test"
  },
  {
    "question": "How do I make Git forget about a file that was tracked, but is now in .gitignore?",
    "answer": ".gitignore will prevent untracked files from being added (without an add -f) to the set of files tracked by Git. However, Git will continue to track any files that are already being tracked.\nUpdated Answer in 2024\nDo NOT use git rm --cached <file> if you ever want to see that file again. It will remove it from git, and also your local machine.\nIf you want to keep the file locally, but remove it from git tracking, use the answer by Konstantin. In short, use the following instead of git rm:\ngit update-index --skip-worktree <file>\nHowever, according to the official git documentation:\n\nUsers often try to use the assume-unchanged and skip-worktree bits to tell Git to ignore changes to files that are tracked. This does not work as expected, since Git may still check working tree files against the index when performing certain operations. In general, Git does not provide a way to ignore changes to tracked files, so alternate solutions are recommended.\n\nTherefore, you should still consider using the original answer below.\nOriginal Answer\nWARNING: This will remove the physical file from your local machine and other developers' machines on your or their next git pull.\nTo stop tracking a file, we must remove it from the index:\ngit rm --cached <file>\n\nTo remove a folder and all files in the folder recursively:\ngit rm -r --cached <folder>\n\nThe removal of the file from the head revision will happen on the next commit."
  },
  {
    "question": "How do I remove local (untracked) files from the current Git working tree?",
    "answer": "git-clean - Remove untracked files from the working tree\nSynopsis\ngit clean [-d] [-f] [-i] [-n] [-q] [-e <pattern>] [-x | -X] [--] <path>…​\n\nDescription\nCleans the working tree by recursively removing files that are not under version control, starting from the current directory.\nNormally, only files unknown to Git are removed, but if the -x option is specified, ignored files are also removed. This can, for example, be useful to remove all build products.\nIf any optional <path>... arguments are given, only those paths are affected.\n\n\nStep 1 is to show what will be deleted by using the -n option:\n\n# Print out the list of files and directories which will be removed (dry run)\ngit clean -n -d\n\nClean Step - beware: this will delete files:\n# Delete the files from the repository\ngit clean -f\n\n\nTo remove directories, run git clean -f -d or git clean -fd\nTo remove ignored files, run git clean -f -X or git clean -fX\nTo remove ignored and non-ignored files, run git clean -f -x or git clean -fx\n\nNote the case difference on the X for the two latter commands.\nIf clean.requireForce is set to \"true\" (the default) in your configuration, one needs to specify -f otherwise nothing will actually happen.\nAgain see the git-clean docs for more information.\n\n\nOptions\n-f, --force\nIf the Git configuration variable clean.requireForce is not set to\nfalse, git clean will refuse to run unless given -f, -n or -i.\n-x\nDon’t use the standard ignore rules read from .gitignore (per\ndirectory) and $GIT_DIR/info/exclude, but do still use the ignore\nrules given with -e options. This allows removing all untracked files,\nincluding build products. This can be used (possibly in conjunction\nwith git reset) to create a pristine working directory to test a clean\nbuild.\n-X\nRemove only files ignored by Git. This may be useful to rebuild\neverything from scratch, but keep manually created files.\n-n, --dry-run\nDon’t actually remove anything, just show what would be done.\n-d\nRemove untracked directories in addition to untracked files. If an\nuntracked directory is managed by a different Git repository, it is\nnot removed by default. Use -f option twice if you really want to\nremove such a directory."
  },
  {
    "question": "How to modify existing, unpushed commit messages?",
    "answer": "Amending the most recent commit message\ngit commit --amend\n\nwill open your editor, allowing you to change the commit message of the most recent commit. Additionally, you can set the commit message directly in the command line with:\ngit commit --amend -m \"New commit message\"\n\n…however, this can make multi-line commit messages or small corrections more cumbersome to enter.\nMake sure you don't have any working copy changes staged before doing this or they will get committed too. (Unstaged changes will not get committed.)\nChanging the message of a commit that you've already pushed to your remote branch\nIf you've already pushed your commit up to your remote branch, then - after amending your commit locally (as described above) - you'll also need to force push the commit with:\ngit push <remote> <branch> --force\n# Or\ngit push <remote> <branch> -f\n\nWarning: force-pushing will overwrite the remote branch with the state of your local one. If there are commits on the remote branch that you don't have in your local branch, you will lose those commits.\nWarning: be cautious about amending commits that you have already shared with other people. Amending commits essentially rewrites them to have different SHA IDs, which poses a problem if other people have copies of the old commit that you've rewritten. Anyone who has a copy of the old commit will need to synchronize their work with your newly re-written commit, which can sometimes be difficult, so make sure you coordinate with others when attempting to rewrite shared commit history, or just avoid rewriting shared commits altogether.\n\nPerform an interactive rebase\nAnother option is to use interactive rebase.\nThis allows you to edit any message you want to update even if it's not the latest message.\nIn order to do a Git squash, follow these steps:\n// n is the number of commits up to the last commit you want to be able to edit\ngit rebase -i HEAD~n\n\nOnce you squash your commits - choose the e/r for editing the message:\n\nImportant note about interactive rebase\nWhen you use git rebase -i HEAD~n there can be more than n commits. Git will \"collect\" all the commits in the last n commits, and if there was a merge somewhere in between that range you will see all the commits as well, so the outcome will be n + .\nGood tip:\nIf you have to do it for more than a single branch and you might face conflicts when amending the content, set up git rerere and let Git resolve those conflicts automatically for you.\n\nDocumentation\n\ngit-commit(1) Manual Page\n\ngit-rebase(1) Manual Page\n\ngit-push(1) Manual Page"
  },
  {
    "question": "How do I revert a Git repository to a previous commit?",
    "answer": "This depends a lot on what you mean by \"revert\".\nTemporarily switch to a different commit\nIf you want to temporarily go back to it, fool around, then come back to where you are, all you have to do is check out the desired commit:\n# This will detach your HEAD, that is, leave you with no branch checked out:\ngit checkout 0d1d7fc32\n\nOr if you want to make commits while you're there, go ahead and make a new branch while you're at it:\ngit checkout -b old-state 0d1d7fc32\n\nTo go back to where you were, just check out the branch you were on again. (If you've made changes, as always when switching branches, you'll have to deal with them as appropriate. You could reset to throw them away; you could stash, checkout, stash pop to take them with you; you could commit them to a branch there if you want a branch there.)\nHard delete unpublished commits\nIf, on the other hand, you want to really get rid of everything you've done since then, there are two possibilities. One, if you haven't published any of these commits, simply reset:\n# This will destroy any local modifications.\n# Don't do it if you have uncommitted work you want to keep.\ngit reset --hard 0d1d7fc32\n\n# Alternatively, if there's work to keep:\ngit stash\ngit reset --hard 0d1d7fc32\ngit stash pop\n# This saves the modifications, then reapplies that patch after resetting.\n# You could get merge conflicts, if you've modified things which were\n# changed since the commit you reset to.\n\nIf you mess up, you've already thrown away your local changes, but you can at least get back to where you were before by resetting again.\nUndo published commits with new commits\nOn the other hand, if you've published the work, you probably don't want to reset the branch, since that's effectively rewriting history. In that case, you could indeed revert the commits. In many enterprise organisations, the concept of \"protected\" branches will even prevent history from being rewritten on some major branches. In this case, reverting is your only option.\nWith Git, revert has a very specific meaning: create a commit with the reverse patch to cancel it out. This way you don't rewrite any history.\nFirst figure out what commits to revert. Depending on the technique chosen below, you want to either revert only the merge commits, or only the non-merge commits.\n\n# This lists all merge commits between 0d1d7fc and HEAD:\ngit log --merges --pretty=format:\"%h\" 0d1d7fc..HEAD | tr '\\n' ' '\n\n# This lists all non merge commits between 0d1d7fc and HEAD:\ngit log --no-merges --pretty=format:\"%h\" 0d1d7fc..HEAD | tr '\\n' ' '\n\nNote: if you revert multiple commits, the order matters. Start with the most recent commit.\n# This will create three separate revert commits, use non merge commits only:\ngit revert a867b4af 25eee4ca 0766c053\n\n# It also takes ranges. This will revert the last two commits:\ngit revert HEAD~2..HEAD\n\n# Similarly, you can revert a range of commits using commit hashes (non inclusive of first hash):\ngit revert 0d1d7fc..a867b4a\n\n# Reverting a merge commit. You can also use a range of merge commits here.\ngit revert -m 1 <merge_commit_sha>\n\n# To get just one, you could use `rebase -i` to squash them afterwards\n# Or, you could do it manually (be sure to do this at top level of the repo)\n# get your index and work tree into the desired state, without changing HEAD:\ngit checkout 0d1d7fc32 .\n\n# Then commit. Be sure and write a good message describing what you just did\ngit commit\n\nThe git-revert manpage actually covers a lot of this in its description. Another useful link is this git-scm.com section discussing git-revert.\nIf you decide you didn't want to revert after all, you can revert the revert (as described here) or reset back to before the revert (see the previous section).\nYou may also find this answer helpful in this case:\nHow can I move HEAD back to a previous location? (Detached head) & Undo commits"
  },
  {
    "question": "How do I change the URI (URL) for a remote Git repository?",
    "answer": "First, view the existing remotes to verify which URL is currently set:\ngit remote -v\n\nThen, you can set it with:\ngit remote set-url origin <NEW_GIT_URL_HERE>\n\nSee git help remote. You also can edit .git/config and change the URLs there.\nYou're not in any danger of losing history unless you do something very silly (and if you're worried, just make a copy of your repo, since your repo is your history.)"
  },
  {
    "question": "Move the most recent commit(s) to a new branch with Git",
    "answer": "WARNING: You need to store uncommitted edits to your stash before doing this, using git stash. Once complete, you can retrieve the stashed uncommitted edits with git stash pop. git reset hard command will remove all changes!\nMoving to an existing branch\nIf you want to move your commits to an existing branch, it will look like this:\ngit checkout existingbranch\ngit merge branchToMoveCommitFrom\ngit checkout branchToMoveCommitFrom\ngit reset --hard HEAD~3 # Go back 3 commits. You *will* lose uncommitted work.\ngit checkout existingbranch\n\nMoving to a new branch\nWARNING: This method works because you are creating a new branch with the first command: git branch newbranch. If you want to move commits to an existing branch you need to merge your changes into the existing branch before executing git reset --hard HEAD~3 (see Moving to an existing branch above). If you don't merge your changes first, they will be lost.\nUnless there are other circumstances involved, this can be easily done by branching and rolling back.\n\n# Note: Any changes not committed will be lost.\ngit branch newbranch      # Create a new branch, saving the desired commits\ngit checkout master       # checkout master, this is the place you want to go back\ngit reset --hard HEAD~3   # Move master back by 3 commits (Make sure you know how many commits you need to go back)\ngit checkout newbranch    # Go to the new branch that still has the desired commits\n\nBut do make sure how many commits to go back. Alternatively, you can instead of HEAD~3, simply provide the hash of the commit (or the reference like origin/master) you want to \"revert back to\" on the master (/current) branch, e.g:\ngit reset --hard a1b2c3d4\n\nNote: You will only be \"losing\" commits from the master branch, but don't worry, you'll have those commits in newbranch! An easy way to check that, after completing the 4 step sequence of commands above, is by looking at git log -n4 which will show the history of newbranch actually retained the 3 commits (and the reason is that newbranch was created at the time those changes were already commited on master!). They have only been removed from master, as git reset only affected the branch that was checked out at the time of its execution, i.e. master (see git reset description: Reset current HEAD to the specified state). git status however will not show any checkouts on the newbranch, which might be surprising at first but that is actually expected.\nLastly, you may need to force push your latest changes to main repo:\ngit push origin master --force\n\nWARNING: With Git version 2.0 and later, if you later git rebase the new branch upon the original (master) branch, you may need an explicit --no-fork-point option during the rebase to avoid losing the carried-over commits.  Having branch.autosetuprebase always set makes this more likely.  See John Mellor's answer for details."
  },
  {
    "question": "How do I discard unstaged changes in Git?",
    "answer": "For all unstaged files in current working directory use:\ngit restore .\n\nFor a specific file use:\ngit restore path/to/file/to/revert\n\nThat together with git switch replaces the overloaded git checkout (see here), and thus removes the argument disambiguation.\nIf a file has both staged and unstaged changes, only the unstaged changes shown in git diff are reverted. Changes shown in git diff --staged stay intact.\nBefore Git 2.23\nFor all unstaged files in current working directory:\ngit checkout -- .\n\nFor a specific file:\ngit checkout -- path/to/file/to/revert\n\n-- here to remove ambiguity (this is known as  argument disambiguation)."
  },
  {
    "question": "Reset local repository branch to be just like remote repository HEAD",
    "answer": "Setting your branch to exactly match the remote branch can be done in two steps:\n\ngit fetch origin\ngit reset --hard origin/master\n\nIf you want to save your current branch's state before doing this (just in case), you can do:\ngit commit -a -m \"Saving my work, just in case\"\ngit branch my-saved-work\n\nNow your work is saved on the branch \"my-saved-work\" in case you decide you want it back (or want to look at it later or diff it against your updated branch).\nNote: the first example assumes that the remote repo's name is origin and that the branch named master in the remote repo matches the currently checked-out branch in your local repo, since that is in line with the example given in the question. If you are trying to reset to the default branch in a more recent repository, it is likely that it will be main.\nBTW, this situation that you're in looks an awful lot like a common case where a push has been done into the currently checked out branch of a non-bare repository. Did you recently push into your local repo? If not, then no worries -- something else must have caused these files to unexpectedly end up modified. Otherwise, you should be aware that it's not recommended to push into a non-bare repository (and not into the currently checked-out branch, in particular)."
  },
  {
    "question": "How can I reset or revert a file to a specific revision?",
    "answer": "Assuming the hash of the commit you want is c5f567:\ngit checkout c5f567 -- file1/to/restore file2/to/restore\n\nThe git checkout man page gives more information.\nIf you want to revert to the commit before c5f567, append ~1 (where 1 is the number of commits you want to go back, it can be anything):\ngit checkout c5f567~1 -- file1/to/restore file2/to/restore\n\nAs a side note, I've always been uncomfortable with this command because it's used for both ordinary things (changing between branches) and unusual, destructive things (discarding changes in the working directory).\nFor the meaning of -- in the command, refer to In Git, what does -- (dash dash) mean?\n\nThere is also a new git restore command that is specifically designed for restoring working copy files that have been modified. If your git is new enough you can use this command, but the documentation comes with a warning:\n\nTHIS COMMAND IS EXPERIMENTAL. THE BEHAVIOR MAY CHANGE.\n\nBecause git restore is experimental, it should not yet be promoted as the primary answer to this question. When the command is no longer marked as \"experimental\", then this answer can be amended to promote the use of git restore. [At the time of writing, the git restore command has been marked as \"experimental\" for at least four years.]"
  },
  {
    "question": "How do I push a new local branch to a remote Git repository and track it too?",
    "answer": "In Git 1.7.0 and later, you can checkout a new branch:\ngit checkout -b <branch>\n\nEdit files, add and commit. Then push with the -u (short for --set-upstream) option:\ngit push -u origin <branch>\n\nGit will set up the tracking information during the push."
  },
  {
    "question": "How do I squash my last N commits together?",
    "answer": "You can do this fairly easily without git rebase or git merge --squash. In this example, we'll squash the last 3 commits.\nIf you want to write the new commit message from scratch, this suffices:\ngit reset --soft HEAD~3\ngit commit\n\nIf you want to start editing the new commit message with a concatenation of the existing commit messages (i.e. similar to what a pick/squash/squash/…/squash git rebase -i instruction list would start you with), then you need to extract those messages and pass them to git commit:\ngit reset --soft HEAD~3 && \ngit commit --edit -m\"$(git log --format=%B --reverse HEAD..HEAD@{1})\"\n\nBoth of those methods squash the last three commits into a single new commit in the same way. The soft reset just re-points HEAD to the last commit that you do not want to squash. Neither the index nor the working tree are touched by the soft reset, leaving the index in the desired state for your new commit (i.e. it already has all the changes from the commits that you are about to “throw away”).\nEdit Based on Comments\nBecause git reset and git rebase rewrite history, you must use the --force flag to push the modified branch to the remote. This is what the --force flag is meant for. You can also be extra careful and fully define your target:\ngit push --force-with-lease origin <branch-name>"
  },
  {
    "question": "How to determine the URL that a local Git repository was originally cloned from",
    "answer": "To obtain only the remote URL:\ngit config --get remote.origin.url\n\nIf you require full output, and you are on a network that can reach the remote repo where the origin resides:\ngit remote show origin\n\nWhen using git clone (from GitHub, or any source repository for that matter) the default name for the source of the clone is \"origin\". Using git remote show will display the information about this remote name. The first few lines should show:\nC:\\Users\\jaredpar\\VsVim> git remote show origin\n* remote origin\n  Fetch URL: git@github.com:jaredpar/VsVim.git\n  Push  URL: git@github.com:jaredpar/VsVim.git\n  HEAD branch: master\n  Remote branches:\n\nIf you want to use the value in a script, you would use the first command listed in this answer."
  },
  {
    "question": "How do I add an empty directory to a Git repository?",
    "answer": "Another way to make a directory stay (almost) empty (in the repository) is to create a .gitignore file inside that directory that contains these four lines:\n\n# Ignore everything in this directory\n*\n# Except this file\n!.gitignore\n\n\nThen you don't have to get the order right the way that you have to do in m104's solution.\n\nThis also gives the benefit that files in that directory won't show up as \"untracked\" when you do a git status.\n\nMaking @GreenAsJade's comment persistent:\n\n\n  I think it's worth noting that this solution does precisely what the question asked for, but is not perhaps what many people looking at this question will have been looking for. This solution guarantees that the directory remains empty. It says \"I truly never want files checked in here\". As opposed to \"I don't have any files to check in here, yet, but I need the directory here, files may be coming later\"."
  },
  {
    "question": "How do I resolve merge conflicts in a Git repository?",
    "answer": "Try:\ngit mergetool\n\nIt opens a GUI that steps you through each conflict, and you get to choose how to merge.  Sometimes it requires a bit of hand editing afterwards, but usually it's enough by itself.  It is much better than doing the whole thing by hand certainly.\n\nAs per Josh Glover's comment:\n\n[This command]\ndoesn't necessarily open a GUI unless you install one. Running git mergetool for me resulted in vimdiff being used. You can install\none of the following tools to use it instead: meld, opendiff,\nkdiff3, tkdiff, xxdiff, tortoisemerge, gvimdiff, diffuse,\necmerge, p4merge, araxis, vimdiff, emerge.\n\n\nBelow is a sample procedure using vimdiff to resolve merge conflicts, based on this link.\n\nRun the following commands in your terminal\ngit config merge.tool vimdiff\ngit config merge.conflictstyle diff3\ngit config mergetool.prompt false\n\nThis will set vimdiff as the default merge tool.\n\nRun the following command in your terminal\ngit mergetool\n\n\nYou will see a vimdiff display in the following format:\n  ╔═══════╦══════╦════════╗\n  ║       ║      ║        ║\n  ║ LOCAL ║ BASE ║ REMOTE ║\n  ║       ║      ║        ║\n  ╠═══════╩══════╩════════╣\n  ║                       ║\n  ║        MERGED         ║\n  ║                       ║\n  ╚═══════════════════════╝\n\nThese 4 views are\n\nLOCAL: this is the file from the current branch\nBASE: the common ancestor, how this file looked before both changes\nREMOTE: the file you are merging into your branch\nMERGED: the merge result; this is what gets saved in the merge commit and used in the future\n\nYou can navigate among these views using ctrl+w. You can directly reach the MERGED view using ctrl+w followed by j.\nMore information about vimdiff navigation is here and here.\n\nYou can edit the MERGED view like this:\n\nIf you want to get changes from REMOTE\n:diffg RE\n\n\nIf you want to get changes from BASE\n:diffg BA\n\n\nIf you want to get changes from LOCAL\n:diffg LO\n\n\n\n\nSave, Exit, Commit, and Clean up\n:wqa save and exit from vi\ngit commit -m \"message\"\ngit clean Remove extra files (e.g. *.orig). Warning: It will remove all untracked files, if you won't pass any arguments."
  },
  {
    "question": "How can I delete a remote tag?",
    "answer": "You can push an 'empty' reference to the remote tag name:\ngit push origin :tagname\n\nOr, more expressively, use the --delete option (or -d if your git version is older than 1.8.0):\ngit push --delete origin tagname\n\nNote that git has tag namespace and branch namespace so you may use the same name for a branch and for a tag. If you want to make sure that you cannot accidentally remove the branch instead of the tag, you can specify full ref which will never delete a branch:\ngit push origin :refs/tags/tagname\n\nIf you also need to delete the local tag, use:\ngit tag --delete tagname\n\nor\ngit tag -d tagname\n\n\nBackground\nPushing a branch, tag, or other ref to a remote repository involves specifying \"which repo, what source, what destination?\"\ngit push remote-repo source-ref:destination-ref\n\nA real world example where you push your master branch to the origin's master branch is:\ngit push origin refs/heads/master:refs/heads/master\n\nWhich because of default paths, can be shortened to:\ngit push origin master:master\n\nTags work the same way:\ngit push origin refs/tags/release-1.0:refs/tags/release-1.0\n\nWhich can also be shortened to:\ngit push origin release-1.0:release-1.0\n\nBy omitting the source ref (the part before the colon), you push 'nothing' to the destination, deleting the ref on the remote end."
  },
  {
    "question": "Undo a Git merge that hasn&#39;t been pushed yet",
    "answer": "With git reflog check which commit is one prior the merge (git reflog will be a better option than git log). Then you can reset it using:\n\ngit reset --hard commit_sha\n\n\nThere's also another way:\n\ngit reset --hard HEAD~1\n\n\nIt will get you back 1 commit.\n\nBe aware that any modified and uncommitted/unstashed files will be reset to their unmodified state. To keep them either stash changes away or see --merge option below.  \n\n\n\nAs @Velmont suggested below in his answer, in this direct case using:\n\ngit reset --hard ORIG_HEAD\n\n\nmight yield better results, as it should preserve your changes. ORIG_HEAD will point to a commit directly before merge has occurred, so you don't have to hunt for it yourself.\n\n\n\nA further tip is to use the --merge switch instead of --hard since it doesn't reset files unnecessarily:\n\ngit reset --merge ORIG_HEAD\n\n\n\n  --merge\n  \n  Resets the index and updates the files in the working tree that are different between <commit> and HEAD, but keeps those which are different between the index and working tree (i.e. which have changes which have not been added)."
  },
  {
    "question": "How do I clone all remote branches?",
    "answer": "First, clone a remote Git repository and cd into it:\n$ git clone git://example.com/myproject\n$ cd myproject\n\nNext, look at the local branches in your repository:\n$ git branch\n* master\n\nBut there are other branches hiding in your repository! See these using the -a flag:\n$ git branch -a\n* master\n  remotes/origin/HEAD\n  remotes/origin/master\n  remotes/origin/v1.0-stable\n  remotes/origin/experimental\n\nTo take a quick peek at an upstream branch, check it out directly:\n$ git checkout origin/experimental\n\nTo work on that branch, create a local tracking branch, which is done automatically by:\n$ git checkout experimental\n\nBranch experimental set up to track remote branch experimental from origin.\nSwitched to a new branch 'experimental'\n\nHere, \"new branch\" simply means that the branch is taken from the index and created locally for you.  As the previous line tells you, the branch is being set up to track the remote branch, which usually means the origin/branch_name branch.\nYour local branches should now show:\n$ git branch\n* experimental\n  master\n\nYou can track more than one remote repository using git remote:\n$ git remote add win32 git://example.com/users/joe/myproject-win32-port\n$ git branch -a\n* master\n  remotes/origin/HEAD\n  remotes/origin/master\n  remotes/origin/v1.0-stable\n  remotes/origin/experimental\n  remotes/win32/master\n  remotes/win32/new-widgets\n\nAt this point, things are getting pretty crazy, so run gitk to see what's going on:\n$ gitk --all &"
  },
  {
    "question": "How do I update or sync a forked repository on GitHub?",
    "answer": "In your local clone of your forked repository, you can add the original GitHub repository as a \"remote\".  (\"Remotes\" are like nicknames for the URLs of repositories - origin is one, for example.)  Then you can fetch all the branches from that upstream repository, and rebase your work to continue working on the upstream version.  In terms of commands that might look like:\n# Add the remote, call it \"upstream\":\n\ngit remote add upstream https://github.com/whoever/whatever.git\n\n# Fetch all the branches of that remote into remote-tracking branches\n\ngit fetch upstream\n\n# Make sure that you're on your main branch:\n\ngit checkout main\n\n# Rewrite your main branch so that any commits of yours that\n# aren't already in upstream/main are replayed on top of that\n# other branch:\n\ngit rebase upstream/main\n\nIf you don't want to rewrite the history of your main branch, (for example because other people may have cloned it) then you should replace the last command with git merge upstream/main.  However, for making further pull requests that are as clean as possible, it's probably better to rebase.\n\nIf you've rebased your branch onto upstream/main you may need to force the push in order to push it to your own forked repository on GitHub.  You'd do that with:\ngit push -f origin main\n\nYou only need to use the -f the first time after you've rebased."
  },
  {
    "question": "How do I remove a submodule?",
    "answer": "In modern git (I'm writing this in 2022, with an updated git installation), this has become quite a bit simpler:\n\nRun git rm <path-to-submodule>, and commit.\n\nThis removes the filetree at <path-to-submodule>, and the submodule's entry in the .gitmodules file. I.e. all traces of the submodule in your repository proper are removed.\nAs the docs note however, the .git dir of the submodule is kept around (in the modules/ directory of the main project's .git dir), \"to make it possible to checkout past commits without requiring fetching from another repository\".\nIf you nonetheless want to remove this info, manually delete the submodule's directory in .git/modules/, and remove the submodule's entry in the file .git/config. These steps can be automated using the commands\n\nrm -rf .git/modules/<path-to-submodule>, and\ngit config --remove-section submodule.<path-to-submodule>.\n\n\n\nCaution: content below is older community wiki instructions.  Ignore if you have a modern git:\nVia the page Git Submodule Tutorial:\nTo remove a submodule you need to:\n\nDelete the relevant section from the .gitmodules file.\nStage the .gitmodules changes:git add .gitmodules\nDelete the relevant section from .git/config.\nRemove the submodule files from the working tree and index:git rm --cached path_to_submodule (no trailing slash).\nRemove the submodule's .git directory:rm -rf .git/modules/path_to_submodule\nCommit the changes:git commit -m \"Removed submodule <name>\"\nDelete the now untracked submodule files:rm -rf path_to_submodule\n\nSee also: alternative steps below."
  },
  {
    "question": "How do I delete a commit from a branch?",
    "answer": "Careful: git reset --hard WILL DELETE YOUR WORKING DIRECTORY CHANGES.\nBe sure to stash any local changes you want to keep before running this command.\nAssuming you are sitting on that commit, then this command will wack it...\ngit reset --hard HEAD~1\n\nThe HEAD~1 means the commit before head.\nOr, you could look at the output of git log, find the commit id of the commit you want to back up to, and then do this:\ngit reset --hard <sha1-commit-id>\n\n\nIf you already pushed it, you will need to do a force push to get rid of it...\ngit push origin HEAD --force\n\nHowever, if others may have pulled it, then you would be better off starting a new branch.  Because when they pull, it will just merge it into their work, and you will get it pushed back up again.\nIf you already pushed, it may be better to use git revert, to create a \"mirror image\" commit that will undo the changes.  However, both commits will be in the log.\n\nFYI: git reset --hard HEAD is great if you want to get rid of WORK IN PROGRESS.It will reset you back to the most recent commit, and erase all the changes in your working tree and index.\ngit stash does the same except you can restore it later if you need, versus permanently delete with reset hard mode. Check your stashes by using git stash list and git stash show 'stash@123'\n\nLastly, if you need to find a commit that you \"deleted\", it is typically present in git reflog unless you have garbage collected your repository."
  },
  {
    "question": "Undoing a git rebase",
    "answer": "The easiest way would be to find the head commit of the branch as it was immediately before the rebase started in the reflog...\ngit reflog\n\nand to reset the current branch to it.\nSuppose the old commit was HEAD@{2} in the ref log:\ngit reset --soft \"HEAD@{2}\"\n\n(If you do not want to retain the working copy changes, you can use --hard instead of --soft)\nYou can check the history of the candidate old head by just doing a git log \"HEAD@{2}\".\nIf you've not disabled per branch reflogs you should be able to simply do git reflog \"branchname@{1}\" as a rebase detaches the branch head before reattaching to the final head. I would double-check this behavior, though, as I haven't verified it recently.\nPer default, all reflogs are activated for non-bare repositories:\n[core]\n    logAllRefUpdates = true"
  },
  {
    "question": "How do I get the current branch name in Git?",
    "answer": "To display only the name of the current branch you're on:\ngit rev-parse --abbrev-ref HEAD\n\nReference: Show just the current branch in Git"
  },
  {
    "question": "Message &#39;src refspec master does not match any&#39; when pushing commits in Git",
    "answer": "Maybe you just need to commit. I ran into this when I did:\nmkdir repo && cd repo\ngit init\ngit remote add origin /path/to/origin.git\ngit add .\n\nOops! Never committed!\ngit push -u origin master\nerror: src refspec master does not match any.\n\nAll I had to do was:\ngit commit -m \"initial commit\"\ngit push origin main\n\nSuccess!"
  },
  {
    "question": "How can I pretty-print JSON in a shell script?",
    "answer": "With Python 2.6+ or 3 you can use the json.tool module:\necho '{\"foo\": \"lorem\", \"bar\": \"ipsum\"}' | python -m json.tool\n\nor, if the JSON is in a file, you can do:\npython -m json.tool my_json.json\n\nif the JSON is from an internet source such as an API, you can use\ncurl http://my_url/ | python -m json.tool\n\nFor convenience in all of these cases you can make an alias:\nalias prettyjson='python -m json.tool'\n\n\nFor even more convenience with a bit more typing to get it ready:\nprettyjson_s() {\n    echo \"$1\" | python -m json.tool\n}\n\nprettyjson_f() {\n    python -m json.tool \"$1\"\n}\n\nprettyjson_w() {\n    curl \"$1\" | python -m json.tool\n}\n\nfor all the above cases. You can put this in .bashrc and it will be available every time in shell. Invoke it like prettyjson_s '{\"foo\": \"lorem\", \"bar\": \"ipsum\"}'.\nNote that as @pnd pointed out in the comments below, in Python 3.5+ the JSON object is no longer sorted by default. To sort, add the --sort-keys flag to the end. I.e. ... | python -m json.tool --sort-keys.\nAnother useful option might be --no-ensure-ascii which disables escaping of non-ASCII characters (new in version 3.9)."
  },
  {
    "question": "How do I copy a folder from remote to local using scp?",
    "answer": "scp -r user@your.server.example.com:/path/to/foo /home/user/Desktop/\n\nBy not including the trailing '/' at the end of foo, you will copy the directory itself (including contents), rather than only the contents of the directory.\nFrom man scp (See online manual)\n\n-r Recursively copy entire directories"
  },
  {
    "question": "Git is not working after macOS update (&quot;xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools&quot;)",
    "answer": "The problem is that Xcode Command-line Tools needs to be updated due to a MacOs update.\n\nDid not run into this on Sonoma.\n\nMaybe Apple fixed the process?\n\n\nUpdated for Ventura\n\nAfter opening the terminal after restarting, I tried to go to my code, and do a git status, and I got an error and prompt for command line software agreement:\nSo press space until you get to the [agree, print, cancel] option, so careful hit space to scroll down to the end, if you blow past It you have to run a command to get it back. Use sudo xcodebuild -license to get to it again.\nJust be careful on scrolling down and enter agree and press return and it will launch into an update.\n\nThen I tried to use git after the install, and it prompted me to install Xcode tools again.\nI followed my own advice from previous years (see below), and went to https://developer.apple.com/download/all and downloaded\n\"Command Line Tools for Xcode 14\" (You have to log in with your Apple ID and enter MFA code, so have all the devices you need for that handy. Then select \"Command Line Tools for Xcode 14\", or if you want to get into the alphas or betas, that's up to you. But stable releases are probably the best choice for software developers.\n\nYou have to either download the tools from CLI or the developer page and before you can use git, you need to reboot!!! Or you will get stuck in a loop of prompt & downloading\nRebooting will break the loop and complete the installation of your CLI tools including git so that you can get back to work\nSolutions for previous years, these may or may not be valid these days as the downloads page has changed significantly:\nPREVIOUS YEARS SOLUTIONS, probably #2 is most helpful.\n*** Solution #1:\nGo back to your terminal and enter:\nxcode-select --install\n\nYou'll then receive the following output:\nxcode-select: note: install requested for command line developer tools\n\nYou will then be prompted in a window to update Xcode Command Line tools. (which could take a while)\nOpen a new terminal window and your development tools should be returned.\nAddition: With any major or semi-major update you'll need to update the command line tools in order to get them functioning properly again. Check Xcode with any update. This goes beyond Mojave...\nAfter that restart your terminal\nAlternatively, IF that fails, and it might.... you'll get a pop-up box saying \"Software not found on server\", proceed to solution 2.\n*** Solution #2: (Preferred method)\nIf you hit xcode-select --install and it doesn't find the software, log into Apple Developer, and install it via webpage.\nLog in or sign up here:\nhttps://developer.apple.com/download/more/\nLook for: \"Command Line Tools for Xcode 14.x\" in the list of downloads\nThen click the dmg and download. (See previous image above) either way, you will probably wind up at an apple downloads webpage."
  },
  {
    "question": "Is there an equivalent of &#39;which&#39; on the Windows command line?",
    "answer": "I suggest you use Windows PowerShell's Get-Command cmdlet, as described in another answer to this question by Marawan Mamdouh.\nIf you're like me and don't use PowerShell, use Windows' where.exe program. Like Unix which, it shows the full path that would match the filename-only command you type:\nC:\\> where edit\nC:\\Windows\\System32\\edit.com\n\nUnlike which, where.exe can show all the paths that match the given filename, though only the first one shown would normally be used when launching a program:\nC:\\> where notepad\nC:\\Windows\\System32\\notepad.exe\nC:\\Windows\\notepad.exe\n\nwhere.exe tries to follow the Windows command shell CMD.EXE's rules for what file names and paths work as commands. That includes the %PATHEXT% environment variable and the ability to open non-program data files using their filenames with extensions:\nC:\\> set pathext\nPATHEXT=.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC\n\nC:\\> where Enterprise.xml slmgr\nC:\\Windows\\Enterprise.xml\nC:\\Windows\\System32\\slmgr.vbs\n\nwhere.exe will even accept wildcards, so where nt*.exe finds all files in your %PATH% and current directory whose names start with nt and end with .exe:\nC:\\> where nt*.exe\nC:\\Windows\\System32\\ntoskrnl.exe\nC:\\Windows\\System32\\ntprint.exe\nC:\\Windows\\System32\\ntvdm.exe\n\nCheck the online docs for where.exe or run where.exe /? for more help.\n\nNotes:\n\nWhen using PowerShell, run where.exe as where.exe, never where. Plain where in PowerShell is an alias for the Where-Object cmdlet, which does something very different from where.exe / which.\nwhere.exe is available in Windows Server 2003 and later. Sorry if you're still on Windows XP."
  },
  {
    "question": "How to change the output color of echo in Linux",
    "answer": "You can use these ANSI escape codes:\nBlack        0;30     Dark Gray     1;30\nRed          0;31     Light Red     1;31\nGreen        0;32     Light Green   1;32\nBrown/Orange 0;33     Yellow        1;33\nBlue         0;34     Light Blue    1;34\nPurple       0;35     Light Purple  1;35\nCyan         0;36     Light Cyan    1;36\nLight Gray   0;37     White         1;37\n\nAnd then use them like this in your script:\n#    .---------- constant part!\n#    vvvv vvvv-- the code from above\nRED='\\033[0;31m'\nNC='\\033[0m' # No Color\nprintf \"I ${RED}love${NC} Stack Overflow\\n\"\n\nwhich prints love in red.\nFrom @james-lim's comment, if you are using the echo command, be sure to use the -e flag to allow backslash escapes.\n#    .---------- constant part!\n#    vvvv vvvv-- the code from above\nRED='\\033[0;31m'\nNC='\\033[0m' # No Color\necho -e \"I ${RED}love${NC} Stack Overflow\"\n\nNote: Don't add \"\\n\" when using echo unless you want to add an additional empty line."
  },
  {
    "question": "How to import an SQL file using the command line in MySQL?",
    "answer": "Try:\nmysql -u username -p database_name < file.sql\n\nCheck MySQL Options.\nNote 1: It is better to use the full path of the SQL file file.sql.\nNote 2: Use -R and --triggers with mysqldump to keep the routines and triggers of the original database. They are not copied by default.\nNote 3 You may have to create the (empty) database from MySQL if it doesn't exist already and the exported SQL doesn't contain CREATE DATABASE (exported with --no-create-db or -n option) before you can import it."
  },
  {
    "question": "How do I parse command line arguments in Bash?",
    "answer": "Bash Space-Separated (e.g., --option argument)\n\ncat >/tmp/demo-space-separated.sh <<'EOF'\n#!/bin/bash\n\nPOSITIONAL_ARGS=()\n\nwhile [[ $# -gt 0 ]]; do\n  case $1 in\n    -e|--extension)\n      EXTENSION=\"$2\"\n      shift # past argument\n      shift # past value\n      ;;\n    -s|--searchpath)\n      SEARCHPATH=\"$2\"\n      shift # past argument\n      shift # past value\n      ;;\n    --default)\n      DEFAULT=YES\n      shift # past argument\n      ;;\n    -*|--*)\n      echo \"Unknown option $1\"\n      exit 1\n      ;;\n    *)\n      POSITIONAL_ARGS+=(\"$1\") # save positional arg\n      shift # past argument\n      ;;\n  esac\ndone\n\nset -- \"${POSITIONAL_ARGS[@]}\" # restore positional parameters\n\necho \"FILE EXTENSION  = ${EXTENSION}\"\necho \"SEARCH PATH     = ${SEARCHPATH}\"\necho \"DEFAULT         = ${DEFAULT}\"\necho \"Number files in SEARCH PATH with EXTENSION:\" $(ls -1 \"${SEARCHPATH}\"/*.\"${EXTENSION}\" | wc -l)\n\nif [[ -n $1 ]]; then\n    echo \"Last line of file specified as non-opt/last argument:\"\n    tail -1 \"$1\"\nfi\nEOF\n\nchmod +x /tmp/demo-space-separated.sh\n\n/tmp/demo-space-separated.sh -e conf -s /etc /etc/hosts\n\nOutput from copy-pasting the block above\nFILE EXTENSION  = conf\nSEARCH PATH     = /etc\nDEFAULT         =\nNumber files in SEARCH PATH with EXTENSION: 14\nLast line of file specified as non-opt/last argument:\n#93.184.216.34    example.com\n\nUsage\ndemo-space-separated.sh -e conf -s /etc /etc/hosts\n\n\nBash Equals-Separated (e.g., --option=argument)\ncat >/tmp/demo-equals-separated.sh <<'EOF'\n#!/bin/bash\n\nfor i in \"$@\"; do\n  case $i in\n    -e=*|--extension=*)\n      EXTENSION=\"${i#*=}\"\n      shift # past argument=value\n      ;;\n    -s=*|--searchpath=*)\n      SEARCHPATH=\"${i#*=}\"\n      shift # past argument=value\n      ;;\n    --default)\n      DEFAULT=YES\n      shift # past argument with no value\n      ;;\n    -*|--*)\n      echo \"Unknown option $i\"\n      exit 1\n      ;;\n    *)\n      ;;\n  esac\ndone\n\necho \"FILE EXTENSION  = ${EXTENSION}\"\necho \"SEARCH PATH     = ${SEARCHPATH}\"\necho \"DEFAULT         = ${DEFAULT}\"\necho \"Number files in SEARCH PATH with EXTENSION:\" $(ls -1 \"${SEARCHPATH}\"/*.\"${EXTENSION}\" | wc -l)\n\nif [[ -n $1 ]]; then\n    echo \"Last line of file specified as non-opt/last argument:\"\n    tail -1 $1\nfi\nEOF\n\nchmod +x /tmp/demo-equals-separated.sh\n\n/tmp/demo-equals-separated.sh -e=conf -s=/etc /etc/hosts\n\nOutput from copy-pasting the block above\nFILE EXTENSION  = conf\nSEARCH PATH     = /etc\nDEFAULT         =\nNumber files in SEARCH PATH with EXTENSION: 14\nLast line of file specified as non-opt/last argument:\n#93.184.216.34    example.com\n\nUsage\ndemo-equals-separated.sh -e=conf -s=/etc /etc/hosts\n\n\nTo better understand ${i#*=} search for \"Substring Removal\" in this guide. It is functionally equivalent to `sed 's/[^=]*=//' <<< \"$i\"` which calls a needless subprocess or `echo \"$i\" | sed 's/[^=]*=//'` which calls two needless subprocesses.\n\nUsing bash with getopt[s]\ngetopt(1) limitations (older, relatively-recent getopt versions):\n\ncan't handle arguments that are empty strings\ncan't handle arguments with embedded whitespace\n\nMore recent getopt versions don't have these limitations. For more information, see these docs.\n\nPOSIX getopts\nAdditionally, the POSIX shell and others offer getopts which doen't have these limitations. I've included a simplistic getopts example.\ncat >/tmp/demo-getopts.sh <<'EOF'\n#!/bin/sh\n\n# A POSIX variable\nOPTIND=1         # Reset in case getopts has been used previously in the shell.\n\n# Initialize our own variables:\noutput_file=\"\"\nverbose=0\n\nwhile getopts \"h?vf:\" opt; do\n  case \"$opt\" in\n    h|\\?)\n      show_help\n      exit 0\n      ;;\n    v)  verbose=1\n      ;;\n    f)  output_file=$OPTARG\n      ;;\n  esac\ndone\n\nshift $((OPTIND-1))\n\n[ \"${1:-}\" = \"--\" ] && shift\n\necho \"verbose=$verbose, output_file='$output_file', Leftovers: $@\"\nEOF\n\nchmod +x /tmp/demo-getopts.sh\n\n/tmp/demo-getopts.sh -vf /etc/hosts foo bar\n\nOutput from copy-pasting the block above\nverbose=1, output_file='/etc/hosts', Leftovers: foo bar\n\nUsage\ndemo-getopts.sh -vf /etc/hosts foo bar\n\nThe advantages of getopts are:\n\nIt's more portable, and will work in other shells like dash.\nIt can handle multiple single options like -vf filename in the typical Unix way, automatically.\n\nThe disadvantage of getopts is that it can only handle short options (-h, not --help) without additional code.\nThere is a getopts tutorial which explains what all of the syntax and variables mean.  In bash, there is also help getopts, which might be informative."
  },
  {
    "question": "How do I set a variable to the output of a command in Bash?",
    "answer": "In addition to backticks `command`, command substitution can be done with $(command) or \"$(command)\", which I find easier to read, and allows for nesting.\nOUTPUT=\"$(ls -1)\"\necho \"${OUTPUT}\"\n\nMULTILINE=\"$(ls \\\n   -1)\"\necho \"${MULTILINE}\"\n\nQuoting (\") does matter to preserve multi-line variable values and it is safer to use with whitespace and special characters such as (*) and therefore advised; it is, however, optional on the right-hand side of an assignment when word splitting is not performed, so OUTPUT=$(ls -1) would work fine."
  },
  {
    "question": "Count number of lines in a non binary file (Like a CSV or a TXT) file in terminal",
    "answer": "Use wc:\n\nwc -l <filename>\n\n\nThis will output the number of lines in <filename>:\n\n$ wc -l /dir/file.txt\n3272485 /dir/file.txt\n\n\nOr, to omit the <filename> from the result use wc -l < <filename>:\n\n$ wc -l < /dir/file.txt\n3272485\n\n\nYou can also pipe data to wc as well:\n\n$ cat /dir/file.txt | wc -l\n3272485\n$ curl yahoo.com --silent | wc -l\n63"
  },
  {
    "question": "How can I get a list of user accounts using the command line in MySQL?",
    "answer": "Use this query:\nSELECT User FROM mysql.user;\n\nWhich will output a table like this:\n+-------+\n| User  |\n+-------+\n| root  |\n+-------+\n| user2 |\n+-------+\n\nAs Matthew Scharley points out in the comments on this answer, you can group by the User column if you'd only like to see unique usernames."
  },
  {
    "question": "How do I run two commands in one line in Windows CMD?",
    "answer": "Like this on all Microsoft OSes since 2000, and still good today:\n\ndir & echo foo\n\n\nIf you want the second command to execute only if the first exited successfully:\n\ndir && echo foo\n\n\nThe single ampersand (&) syntax to execute multiple commands on one line goes back to Windows XP, Windows 2000, and some earlier NT versions. (4.0 at least, according to one commenter here.)\n\nThere are quite a few other points about this that you'll find scrolling down this page.\n\nHistorical data follows, for those who may find it educational.\n\nPrior to that, the && syntax was only a feature of the shell replacement 4DOS before that feature was added to the Microsoft command interpreter.\n\nIn Windows 95, 98 and ME, you'd use the pipe character instead:\n\ndir | echo foo\n\n\nIn MS-DOS 5.0 and later, through some earlier Windows and NT versions of the command interpreter, the (undocumented) command separator was character 20 (Ctrl+T) which I'll represent with ^T here.\n\ndir ^T echo foo"
  },
  {
    "question": "git undo all uncommitted or unsaved changes",
    "answer": "This will unstage all files you might have staged with git add:\n  git reset\n\n\nThis will revert all local uncommitted changes (should be executed in repo root):\n  git checkout .\n\nYou can also revert uncommitted changes only to particular file or directory:\n  git checkout [some_dir|file.txt]\n\nYet another way to revert all uncommitted changes (longer to type, but works from any subdirectory):\n  git reset --hard HEAD\n\n\nThis will remove all local untracked files, so only git tracked files remain:\n  git clean -fdx\n\n\nWARNING: -x  will also remove all ignored files, including ones specified by .gitignore! You may want to use -n for preview of files to be deleted.\n\n\n\n\nTo sum it up: executing commands below is basically equivalent to fresh git clone from original source (but it does not re-download anything, so is much faster):\ngit reset\ngit checkout .\ngit clean -fdx\n\nTypical usage for this would be in build scripts, when you must make sure that your tree is absolutely clean - does not have any modifications or locally created object files or build artefacts, and you want to make it work very fast and to not re-clone whole repository every single time."
  },
  {
    "question": "How to reload .bash_profile from the command line",
    "answer": "Simply type source ~/.bash_profile\nAlternatively, if you like saving keystrokes, you can type . ~/.bash_profile"
  },
  {
    "question": "How to pass command line arguments to a rake task",
    "answer": "You can specify formal arguments in rake by adding symbol arguments to the task call.  For example:\n\nrequire 'rake'\n\ntask :my_task, [:arg1, :arg2] do |t, args|\n  puts \"Args were: #{args} of class #{args.class}\"\n  puts \"arg1 was: '#{args[:arg1]}' of class #{args[:arg1].class}\"\n  puts \"arg2 was: '#{args[:arg2]}' of class #{args[:arg2].class}\"\nend\n\ntask :invoke_my_task do\n  Rake.application.invoke_task(\"my_task[1, 2]\")\nend\n\n# or if you prefer this syntax...\ntask :invoke_my_task_2 do\n  Rake::Task[:my_task].invoke(3, 4)\nend\n\n# a task with prerequisites passes its \n# arguments to it prerequisites\ntask :with_prerequisite, [:arg1, :arg2] => :my_task #<- name of prerequisite task\n\n# to specify default values, \n# we take advantage of args being a Rake::TaskArguments object\ntask :with_defaults, :arg1, :arg2 do |t, args|\n  args.with_defaults(:arg1 => :default_1, :arg2 => :default_2)\n  puts \"Args with defaults were: #{args}\"\nend\n\n\nThen, from the command line:\n\n\n> rake my_task[1,false]\nArgs were: {:arg1=>\"1\", :arg2=>\"false\"} of class Rake::TaskArguments\narg1 was: '1' of class String\narg2 was: 'false' of class String\n\n> rake \"my_task[1, 2]\"\nArgs were: {:arg1=>\"1\", :arg2=>\"2\"}\n\n> rake invoke_my_task\nArgs were: {:arg1=>\"1\", :arg2=>\"2\"}\n\n> rake invoke_my_task_2\nArgs were: {:arg1=>3, :arg2=>4}\n\n> rake with_prerequisite[5,6]\nArgs were: {:arg1=>\"5\", :arg2=>\"6\"}\n\n> rake with_defaults\nArgs with defaults were: {:arg1=>:default_1, :arg2=>:default_2}\n\n> rake with_defaults['x','y']\nArgs with defaults were: {:arg1=>\"x\", :arg2=>\"y\"}\n\n\nAs demonstrated in the second example, if you want to use spaces, the quotes around the target name are necessary to keep the shell from splitting up the arguments at the space.\n\nLooking at the code in rake.rb, it appears that rake does not parse task strings to extract arguments for prerequisites, so you can't do task :t1 => \"dep[1,2]\".  The only way to specify different arguments for a prerequisite would be to invoke it explicitly within the dependent task action, as in :invoke_my_task and :invoke_my_task_2.\n\nNote that some shells (like zsh) require you to escape the brackets: rake my_task\\['arg1'\\]"
  },
  {
    "question": "List all environment variables from the command line",
    "answer": "Just do:\n\nSET\n\n\nYou can also do SET prefix to see all variables with names starting with prefix.\n\nFor example, if you want to read only derbydb from the environment variables, do the following: \n\nset derby \n\n\n...and you will get the following: \n\nDERBY_HOME=c:\\Users\\amro-a\\Desktop\\db-derby-10.10.1.1-bin\\db-derby-10.10.1.1-bin"
  },
  {
    "question": "Including all the jars in a directory within the Java classpath",
    "answer": "Using Java 6 or later, the classpath option supports wildcards. Note the following:\n\nUse straight quotes (\")\nUse *, not *.jar\n\nWindows\n\njava -cp \"Test.jar;lib/*\" my.package.MainClass\n\nUnix\n\njava -cp \"Test.jar:lib/*\" my.package.MainClass\n\nThis is similar to Windows, but uses : instead of ;. If you cannot use wildcards, bash allows the following syntax (where lib is the directory containing all the Java archive files):\n\njava -cp \"$(printf %s: lib/*.jar)\"\n\n(Note that using a classpath is incompatible with the -jar option. See also: Execute jar file with multiple classpath libraries from command prompt)\nUnderstanding Wildcards\nFrom the Classpath document:\n\nClass path entries can contain the basename wildcard character *, which is considered equivalent to specifying a list of all the files\nin the directory with the extension .jar or .JAR. For example, the\nclass path entry foo/* specifies all JAR files in the directory named\nfoo. A classpath entry consisting simply of * expands to a list of all\nthe jar files in the current directory.\nA class path entry that contains * will not match class files. To\nmatch both classes and JAR files in a single directory foo, use either\nfoo;foo/* or foo/*;foo. The order chosen determines whether the\nclasses and resources in foo are loaded before JAR files in foo, or\nvice versa.\nSubdirectories are not searched recursively. For example, foo/* looks\nfor JAR files only in foo, not in foo/bar, foo/baz, etc.\nThe order in which the JAR files in a directory are enumerated in the\nexpanded class path is not specified and may vary from platform to\nplatform and even from moment to moment on the same machine. A\nwell-constructed application should not depend upon any particular\norder. If a specific order is required then the JAR files can be\nenumerated explicitly in the class path.\nExpansion of wildcards is done early, prior to the invocation of a\nprogram's main method, rather than late, during the class-loading\nprocess itself. Each element of the input class path containing a\nwildcard is replaced by the (possibly empty) sequence of elements\ngenerated by enumerating the JAR files in the named directory. For\nexample, if the directory foo contains a.jar, b.jar, and c.jar, then\nthe class path foo/* is expanded into foo/a.jar;foo/b.jar;foo/c.jar,\nand that string would be the value of the system property\njava.class.path.\nThe CLASSPATH environment variable is not treated any differently from\nthe -classpath (or -cp) command-line option. That is, wildcards are\nhonored in all these cases. However, class path wildcards are not\nhonored in the Class-Path jar-manifest header.\n\nNote: due to a known bug in java 8, the windows examples must use a backslash preceding entries with a trailing asterisk: https://bugs.openjdk.java.net/browse/JDK-8131329"
  },
  {
    "question": "How to iterate over arguments in a Bash script",
    "answer": "Use \"$@\" to represent all the arguments:\nfor var in \"$@\"\ndo\n    echo \"$var\"\ndone\n\nThis will iterate over each argument and print it out on a separate line.  $@ behaves like $* except that, when quoted, the arguments are broken up properly if there are spaces in them:\nsh test.sh 1 2 '3 4'\n1\n2\n3 4"
  },
  {
    "question": "How can I get the current date and time in the terminal and set a custom command in the terminal for it?",
    "answer": "The command is date\n\nTo customise the output there are a myriad of options available, see date --help for a list.\n\nFor example, date '+%A %W %Y %X' gives Tuesday 34 2013 08:04:22 which is the name of the day of the week, the week number, the year and the time."
  },
  {
    "question": "How do I get the application exit code from a Windows command line?",
    "answer": "The \"exit code\" is stored in a shell variable named errorlevel.\nThe errorlevel is set at the end of a console application. Windows applications behave a little differently; see @gary's answer below.\nUse the if command keyword errorlevel for comparison:\nif errorlevel <n> (<statements>)\n\nWhich will execute statements when the errorlevel is greater than or equal to n. Execute if /? for details.\nA shell variable named errorlevel contains the value as a string and can be dereferenced by wrapping with %'s.\nExample script:\nmy_nifty_exe.exe\n\nrem Give resolution instructions for known exit codes.\nrem Ignore exit code 1.\nrem Otherwise give a generic error message.\n\nif %errorlevel%==7 (\n   echo \"Replace magnetic tape.\"\n) else if %errorlevel%==3 (\n   echo \"Extinguish the printer.\"\n) else if errorlevel 2 (\n   echo Unknown Error: %errorlevel% refer to Run Book documentation.\n) else (\n   echo \"Success!\"\n)\n\nWarning: An environment variable named errorlevel, if it exists, will override the shell variable named errorlevel. if errorlevel tests are not affected."
  },
  {
    "question": "Use grep --exclude/--include syntax to not grep through certain files",
    "answer": "Use the shell globbing syntax:\ngrep pattern -r --include=\\*.cpp --include=\\*.h rootdir\n\nThe syntax for --exclude is identical.\nNote that the star is escaped with a backslash to prevent it from being expanded by the shell (quoting it, such as --include=\"*.cpp\", would work just as well).  Otherwise, if you had any files in the current working directory that matched the pattern, the command line would expand to something like grep pattern -r --include=foo.cpp --include=bar.cpp rootdir, which would only search files named foo.cpp and bar.cpp, which is quite likely not what you wanted.\nUpdate 2021-03-04\nI've edited the original answer to remove the use of brace expansion, which is a feature provided by several shells such as Bash and zsh to simplify patterns like this; but note that brace expansion is not POSIX shell-compliant.\nThe original example was:\ngrep pattern -r --include=\\*.{cpp,h} rootdir\n\nto search through all .cpp and .h files rooted in the directory rootdir."
  },
  {
    "question": "How to force cp to overwrite without confirmation",
    "answer": "You can do yes | cp -rf xxx yyy, but my gutfeeling says that if you do it as root - your .bashrc or .profile has an alias of cp to cp -i, most modern systems (primarily RH-derivatives) do that to root profiles. \n\nYou can check existing aliases by running alias at the command prompt, or which cp to check aliases only for cp.\n\nIf you do have an alias defined, running unalias cp will abolish that for the current session, otherwise you can just remove it from your shell profile.\n\nYou can temporarily bypass an alias and use the non-aliased version of a command by prefixing it with \\, e.g. \\cp whatever"
  },
  {
    "question": "How can I reverse the order of lines in a file?",
    "answer": "Also worth mentioning: tac (the, ahem, reverse of cat). Part of coreutils.\n\nFlipping one file into another\n\ntac a.txt > b.txt"
  },
  {
    "question": "How can I redirect Windows cmd standard output and standard error to a single file?",
    "answer": "You want:\ndir > a.txt 2>&1\n\nThe syntax 2>&1 will redirect 2 (stderr) to 1 (stdout). You can also hide messages by redirecting to NUL. More explanation and examples are on the Microsoft documentation page Redirecting error messages from Command Prompt: STDERR/STDOUT."
  },
  {
    "question": "How can I read and process (parse) command line arguments?",
    "answer": "import sys\n\nprint(\"\\n\".join(sys.argv))\n\nsys.argv is a list that contains all the arguments passed to the script on the command line. sys.argv[0] is the script name.\nBasically,\nimport sys\n\nprint(sys.argv[1:])"
  },
  {
    "question": "Run a PostgreSQL .sql file using command line arguments",
    "answer": "Of course, you will get a fatal error for authenticating, because you do not include a user name...\n\nTry this one, it is OK for me :)\n\npsql -U username -d myDataBase -a -f myInsertFile\n\n\nIf the database is remote, use the same command with host\n\npsql -h host -U username -d myDataBase -a -f myInsertFile"
  },
  {
    "question": "Run Command Prompt Commands",
    "answer": "this is all you have to do run shell commands from C#\nstring strCmdText;\nstrCmdText= \"/C copy /b Image1.jpg + Archive.rar Image2.jpg\";\nSystem.Diagnostics.Process.Start(\"CMD.exe\",strCmdText);\n\nEDIT:\nThis is to hide the cmd window.\nSystem.Diagnostics.Process process = new System.Diagnostics.Process();\nSystem.Diagnostics.ProcessStartInfo startInfo = new System.Diagnostics.ProcessStartInfo();\nstartInfo.WindowStyle = System.Diagnostics.ProcessWindowStyle.Hidden;\nstartInfo.FileName = \"cmd.exe\";\nstartInfo.Arguments = \"/C copy /b Image1.jpg + Archive.rar Image2.jpg\";\nprocess.StartInfo = startInfo;\nprocess.Start();\n\nEDIT 2:\nIt is important that the argument begins with /C, otherwise it won't work. As @scott-ferguson said: /C carries out the command specified by the string and then terminates."
  },
  {
    "question": "Adding a directory to the PATH environment variable in Windows",
    "answer": "Option 1\nAfter you change PATH with the GUI, close and reopen the console window. This works because only programs started after the change will \"see\" the new PATH. This is because when you change the PATH environment variable using the GUI tool, it updates the variable for future processes but not for anything currently running.\nOption 2\nThis option only affects your current shell session, not the whole system. Execute this command in the command window you have open:\nset PATH=%PATH%;C:\\your\\path\\here\\\n\nThis command appends C:\\your\\path\\here\\ to the current PATH. If your path includes spaces, you do not need to include quotation marks.\nBreaking it down:\n\nset – A command that changes cmd's environment variables only for the current cmd session; other programs and the system are unaffected.\nPATH= – This signifies that PATH is the environment variable to be temporarily changed.\n%PATH%;C:\\your\\path\\here\\ – The %PATH% part expands to the current value of PATH, and ;C:\\your\\path\\here\\ is then concatenated to it. This becomes the new PATH."
  },
  {
    "question": "How do I access command line arguments?",
    "answer": "Python tutorial explains it:\n\nimport sys\n\nprint(sys.argv)\n\n\nMore specifically, if you run python example.py one two three:\n\n>>> import sys\n>>> print(sys.argv)\n['example.py', 'one', 'two', 'three']"
  },
  {
    "question": "Linux command to print directory structure in the form of a tree",
    "answer": "Is this what you're looking for tree? It should be in most distributions (maybe as an optional install).\n~> tree -d /proc/self/\n/proc/self/\n|-- attr\n|-- cwd -> /proc\n|-- fd\n|   `-- 3 -> /proc/15589/fd\n|-- fdinfo\n|-- net\n|   |-- dev_snmp6\n|   |-- netfilter\n|   |-- rpc\n|   |   |-- auth.rpcsec.context\n|   |   |-- auth.rpcsec.init\n|   |   |-- auth.unix.gid\n|   |   |-- auth.unix.ip\n|   |   |-- nfs4.idtoname\n|   |   |-- nfs4.nametoid\n|   |   |-- nfsd.export\n|   |   `-- nfsd.fh\n|   `-- stat\n|-- root -> /\n`-- task\n    `-- 15589\n        |-- attr\n        |-- cwd -> /proc\n        |-- fd\n        | `-- 3 -> /proc/15589/task/15589/fd\n        |-- fdinfo\n        `-- root -> /\n\n27 directories\n\nsample taken from maintainer's web page.\nYou can add the option -L # where # is replaced by a number, to specify the max recursion depth.\nRemove -d to display also files."
  },
  {
    "question": "How do I specify a password to &#39;psql&#39; non-interactively?",
    "answer": "Set the PGPASSWORD environment variable inside the script before calling psql\nPGPASSWORD=pass1234 psql -U MyUsername myDatabaseName\n\nFor reference, see http://www.postgresql.org/docs/current/static/libpq-envars.html\n\nEdit\nSince Postgres 9.2 there is also the option to specify a connection string or URI that can contain the username and password.  Syntax is:\n$ psql postgresql://[user[:password]@][host][:port][,...][/dbname][?param1=value1&...]\n\nUsing that is a security risk because the password is visible in plain text when looking at the command line of a running process e.g. using ps (Linux), ProcessExplorer (Windows) or similar tools, by other users.\nSee also this question on Database Administrators"
  },
  {
    "question": "How do I execute a program or call a system command?",
    "answer": "Use subprocess.run:\nimport subprocess\n\nsubprocess.run([\"ls\", \"-l\"]) \n\nAnother common way is os.system but you shouldn't use it because it is unsafe if any parts of the command come from outside your program or can contain spaces or other special characters, also subprocess.run is generally more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc.). Even the documentation for os.system recommends using subprocess instead.\nOn Python 3.4 and earlier, use subprocess.call instead of .run:\nsubprocess.call([\"ls\", \"-l\"])"
  },
  {
    "question": "How do I check if a directory exists or not in a Bash shell script?",
    "answer": "To check if a directory exists:\nif [ -d \"$DIRECTORY\" ]; then\n  echo \"$DIRECTORY does exist.\"\nfi\n\nTo check if a directory does not exist:\nif [ ! -d \"$DIRECTORY\" ]; then\n  echo \"$DIRECTORY does not exist.\"\nfi\n\n\nHowever, as Jon Ericson points out, subsequent commands may not work as intended if you do not take into account that a symbolic link to a directory will also pass this check.\nE.g. running this:\nln -s \"$ACTUAL_DIR\" \"$SYMLINK\"\nif [ -d \"$SYMLINK\" ]; then \n  rmdir \"$SYMLINK\" \nfi\n\nWill produce the error message:\nrmdir: failed to remove `symlink': Not a directory\n\nSo symbolic links may have to be treated differently, if subsequent commands expect directories:\nif [ -d \"$LINK_OR_DIR\" ]; then \n  if [ -L \"$LINK_OR_DIR\" ]; then\n    # It is a symlink!\n    # Symbolic link specific commands go here.\n    rm \"$LINK_OR_DIR\"\n  else\n    # It's a directory!\n    # Directory command goes here.\n    rmdir \"$LINK_OR_DIR\"\n  fi\nfi\n\n\nTake particular note of the double-quotes used to wrap the variables. The reason for this is explained by 8jean in another answer.\nIf the variables contain spaces or other unusual characters it will probably cause the script to fail."
  },
  {
    "question": "How to check if a string contains a substring in Bash",
    "answer": "You can use Marcus's answer (* wildcards) outside a case statement, too, if you use double brackets:\n\nstring='My long string'\nif [[ $string == *\"My long\"* ]]; then\n  echo \"It's there!\"\nfi\n\n\nNote that spaces in the needle string need to be placed between double quotes, and the * wildcards should be outside. Also note that a simple comparison operator is used (i.e. ==), not the regex operator =~."
  },
  {
    "question": "How to concatenate string variables in Bash",
    "answer": "foo=\"Hello\"\nfoo=\"${foo} World\"\necho \"${foo}\"\n> Hello World\n\n\nIn general to concatenate two variables you can just write them one after another:\n\na='Hello'\nb='World'\nc=\"${a} ${b}\"\necho \"${c}\"\n> Hello World"
  },
  {
    "question": "How do I copy a folder from remote to local using scp?",
    "answer": "scp -r user@your.server.example.com:/path/to/foo /home/user/Desktop/\n\nBy not including the trailing '/' at the end of foo, you will copy the directory itself (including contents), rather than only the contents of the directory.\nFrom man scp (See online manual)\n\n-r Recursively copy entire directories"
  },
  {
    "question": "What does &quot; 2&gt;&amp;1 &quot; mean?",
    "answer": "File descriptor 1 is the standard output (stdout).\nFile descriptor 2 is the standard error (stderr).\nAt first, 2>1 may look like a good way to redirect stderr to stdout. However, it will actually be interpreted as \"redirect stderr to a file named 1\".\n& indicates that what follows and precedes is a file descriptor, and not a filename. Thus, we use 2>&1. Consider >& to be a redirect merger operator."
  },
  {
    "question": "How can I recursively find all files in current and subfolders based on wildcard matching?",
    "answer": "Use find:\nfind . -name \"foo*\"\n\nfind needs a starting point, so the . (dot) points to the current directory.\nIf you need case insensitive search use :\nfind . -iname \"foo*\""
  },
  {
    "question": "How do I split a string on a delimiter in Bash?",
    "answer": "You can set the internal field separator (IFS) variable, and then let it parse into an array. When this happens in a command, then the assignment to IFS only takes place to that single command's environment (to read ). It then parses the input according to the IFS variable value into an array, which we can then iterate over.\nThis example will parse one line of items separated by ;, pushing it into an array:\nIFS=';' read -ra ADDR <<< \"$IN\"\nfor i in \"${ADDR[@]}\"; do\n  # process \"$i\"\ndone\n\nThis other example is for processing the whole content of $IN, each time one line of input separated by ;:\nwhile IFS=';' read -ra ADDR; do\n  for i in \"${ADDR[@]}\"; do\n    # process \"$i\"\n  done\ndone <<< \"$IN\""
  },
  {
    "question": "How to mkdir only if a directory does not already exist?",
    "answer": "Try mkdir -p:\n\nmkdir -p foo\n\n\nNote that this will also create any intermediate directories that don't exist; for instance,\n\nmkdir -p foo/bar/baz\n\n\nwill create directories foo, foo/bar, and foo/bar/baz if they don't exist.\n\nSome implementation like GNU mkdir include mkdir --parents as a more readable alias, but this is not specified in POSIX/Single Unix Specification and not available on many common platforms like macOS, various BSDs, and various commercial Unixes, so it should be avoided.\n\nIf you want an error when parent directories don't exist, and want to create the directory if it doesn't exist, then you can test for the existence of the directory first:\n\n[ -d foo ] || mkdir foo"
  },
  {
    "question": "How do I set a variable to the output of a command in Bash?",
    "answer": "In addition to backticks `command`, command substitution can be done with $(command) or \"$(command)\", which I find easier to read, and allows for nesting.\nOUTPUT=\"$(ls -1)\"\necho \"${OUTPUT}\"\n\nMULTILINE=\"$(ls \\\n   -1)\"\necho \"${MULTILINE}\"\n\nQuoting (\") does matter to preserve multi-line variable values and it is safer to use with whitespace and special characters such as (*) and therefore advised; it is, however, optional on the right-hand side of an assignment when word splitting is not performed, so OUTPUT=$(ls -1) would work fine."
  },
  {
    "question": "How to check if a variable is set in Bash",
    "answer": "(Usually) The right way\nif [ -z ${var+x} ]; then echo \"var is unset\"; else echo \"var is set to '$var'\"; fi\n\nwhere ${var+x} is a parameter expansion which evaluates to nothing if var is unset, and substitutes the string x otherwise.\nQuotes Digression\nQuotes can be omitted (so we can say ${var+x} instead of \"${var+x}\") because this syntax & usage guarantees this will only expand to something that does not require quotes (since it either expands to x (which contains no word breaks so it needs no quotes), or to nothing (which results in [ -z  ], which conveniently evaluates to the same value (true) that [ -z \"\" ] does as well)).\nHowever, while quotes can be safely omitted, and it was not immediately obvious to all (it wasn't even apparent to the first author of this quotes explanation who is also a major Bash coder), it would sometimes be better to write the solution with quotes as [ -z \"${var+x}\" ], at the very small possible cost of an O(1) speed penalty.  The first author also added this as a comment next to the code using this solution giving the URL to this answer, which now also includes the explanation for why the quotes can be safely omitted.\n(Often) The wrong way\nif [ -z \"$var\" ]; then echo \"var is blank\"; else echo \"var is set to '$var'\"; fi\n\nThis is often wrong because it doesn't distinguish between a variable that is unset and a variable that is set to the empty string. That is to say, if var='', then the above solution will output \"var is blank\".\nThe distinction between unset and \"set to the empty string\" is essential in situations where the user has to specify an extension, or additional list of properties, and that not specifying them defaults to a non-empty value, whereas specifying the empty string should make the script use an empty extension or list of additional properties.\nThe distinction may not be essential in every scenario though. In those cases  [ -z \"$var\" ] will be just fine."
  },
  {
    "question": "How to delete from a text file, all lines that contain a specific string?",
    "answer": "To remove the line and print the output to standard out:\n\nsed '/pattern to match/d' ./infile\n\n\nTo directly modify the file – does not work with BSD sed:\n\nsed -i '/pattern to match/d' ./infile\n\n\nSame, but for BSD sed (Mac OS X and FreeBSD) – does not work with GNU sed:\n\nsed -i '' '/pattern to match/d' ./infile\n\n\nTo directly modify the file (and create a backup) – works with BSD and GNU sed:\n\nsed -i.bak '/pattern to match/d' ./infile"
  },
  {
    "question": "Loop through an array of strings in Bash?",
    "answer": "You can use it like this:\n\n## declare an array variable\ndeclare -a arr=(\"element1\" \"element2\" \"element3\")\n\n## now loop through the above array\nfor i in \"${arr[@]}\"\ndo\n   echo \"$i\"\n   # or do whatever with individual element of the array\ndone\n\n# You can access them using echo \"${arr[0]}\", \"${arr[1]}\" also\n\n\nAlso works for multi-line array declaration\n\ndeclare -a arr=(\"element1\" \n                \"element2\" \"element3\"\n                \"element4\"\n                )"
  },
  {
    "question": "How do I exclude a directory when using `find`?",
    "answer": "If -prune doesn't work for you, this will:\nfind -name \"*.js\" -not -path \"./directory/*\"\n\nCaveat: requires traversing all of the unwanted directories."
  },
  {
    "question": "How to reload .bashrc settings without logging out and back in again?",
    "answer": "You can enter the long form command:\nsource ~/.bashrc\n\nor you can use the shorter version of the command:\n. ~/.bashrc"
  },
  {
    "question": "How do I iterate over a range of numbers defined by variables in Bash?",
    "answer": "for i in $(seq 1 $END); do echo $i; done\n\nedit: I prefer seq over the other methods because I can actually remember it ;)"
  },
  {
    "question": "How can I count all the lines of code in a directory recursively?",
    "answer": "Try:\nfind . -name '*.php' | xargs wc -l\n\nor (when file names include special characters such as spaces)\nfind . -name '*.php' | sed 's/.*/\"&\"/' | xargs  wc -l\n\nThe SLOCCount tool may help as well.\nIt will give an accurate source lines of code count for whatever\nhierarchy you point it at, as well as some additional stats.\nSorted output:\nfind . -name '*.php' | xargs wc -l | sort -nr"
  },
  {
    "question": "Check existence of input argument in a Bash shell script",
    "answer": "It is:\nif [ $# -eq 0 ]\n  then\n    echo \"No arguments supplied\"\nfi\n\nThe $# variable will tell you the number of input arguments the script was passed.\nOr you can check if an argument is an empty string or not like:\nif [ -z \"$1\" ]\n  then\n    echo \"No argument supplied\"\nfi\n\nThe -z switch will test if the expansion of \"$1\" is a null string or not. If it is a null string then the body is executed."
  },
  {
    "question": "How do I prompt for Yes/No/Cancel input in a Linux shell script?",
    "answer": "A widely available method to get user input at a shell prompt is the read command. Here is a demonstration:\nwhile true; do\n    read -p \"Do you wish to install this program? \" yn\n    case $yn in\n        [Yy]* ) make install; break;;\n        [Nn]* ) exit;;\n        * ) echo \"Please answer yes or no.\";;\n    esac\ndone\n\n\nAnother method, pointed out by Steven Huwig, is Bash's select command. Here is the same example using select:\necho \"Do you wish to install this program?\"\nselect yn in \"Yes\" \"No\"; do\n    case $yn in\n        Yes ) make install; break;;\n        No ) exit;;\n    esac\ndone\n\nWith select you don't need to sanitize the input – it displays the available choices, and you type a number corresponding to your choice. It also loops automatically, so there's no need for a while true loop to retry if they give invalid input. If you want to allow more flexible input (accepting the words of the options, rather than just their number), you can alter it like this:\necho \"Do you wish to install this program?\"\nselect strictreply in \"Yes\" \"No\"; do\n    relaxedreply=${strictreply:-$REPLY}\n    case $relaxedreply in\n        Yes | yes | y ) make install; break;;\n        No  | no  | n ) exit;;\n    esac\ndone\n\n\nAlso, Léa Gris demonstrated a way to make the request language agnostic in her answer. Adapting my first example to better serve multiple languages might look like this:\nset -- $(locale LC_MESSAGES)\nyesexpr=\"$1\"; noexpr=\"$2\"; yesword=\"$3\"; noword=\"$4\"\n\nwhile true; do\n    read -p \"Install (${yesword} / ${noword})? \" yn\n    if [[ \"$yn\" =~ $yesexpr ]]; then make install; exit; fi\n    if [[ \"$yn\" =~ $noexpr ]]; then exit; fi\n    echo \"Answer ${yesword} / ${noword}.\"\ndone\n\nObviously other communication strings remain untranslated here (Install, Answer) which would need to be addressed in a more fully completed translation, but even a partial translation would be helpful in many cases.\n\nFinally, please check out the excellent answer by F. Hauri."
  },
  {
    "question": "Difference between sh and Bash",
    "answer": "What is sh?\nsh (or the Shell Command Language) is a programming language described by the POSIX standard. It has many implementations (ksh88, Dash, ...). Bash can also be considered an implementation of sh (see below).\nBecause sh is a specification, not an implementation, /bin/sh is a symlink (or a hard link) to an actual implementation on most POSIX systems.\nWhat is Bash?\nBash started as an sh-compatible implementation (although it predates the POSIX standard by a few years), but as time passed it has acquired many extensions. Many of these extensions may change the behavior of valid POSIX shell scripts, so by itself Bash is not a valid POSIX shell. Rather, it is a dialect of the POSIX shell language.\nBash supports a --posix switch, which makes it more POSIX-compliant. It also tries to mimic POSIX if invoked as sh.\nsh = bash?\nFor a long time, /bin/sh used to point to /bin/bash on most GNU/Linux systems. As a result, it had almost become safe to ignore the difference between the two. But that started to change recently.\nSome popular examples of systems where /bin/sh does not point to /bin/bash (and on some of which /bin/bash may not even exist) are:\n\nModern Debian and Ubuntu systems, which symlink sh to dash by default;\nBusybox, which is usually run during the Linux system boot time as part of initramfs. It uses the ash shell implementation.\nBSD systems, and in general any non-Linux systems. OpenBSD uses pdksh, a descendant of the KornShell. FreeBSD's sh is a descendant of the original Unix Bourne shell.  Solaris has its own sh which for a long time was not POSIX-compliant; a free implementation is available from the Heirloom project.\n\nHow can you find out what /bin/sh points to on your system?\nThe complication is that /bin/sh could be a symbolic link or a hard link. If it's a symbolic link, a portable way to resolve it is:\n% file -h /bin/sh\n/bin/sh: symbolic link to bash\n\nIf it's a hard link, try\n% find -L /bin -samefile /bin/sh\n/bin/sh\n/bin/bash\n\nIn fact, the -L flag covers both symlinks and hardlinks,\nbut the disadvantage of this method is that it is not portable —\nPOSIX does not require find to support the -samefile option, although both GNU find and FreeBSD find support it.\nShebang line\nUltimately, it's up to you to decide which one to use, by writing the «shebang» line as the very first line of the script.\nE.g.\n#!/bin/sh\n\nwill use sh (and whatever that happens to point to),\n#!/bin/bash\n\nwill use /bin/bash if it's available (and fail with an error message if it's not). Of course, you can also specify another implementation, e.g.\n#!/bin/dash\n\nWhich one to use\nFor my own scripts, I prefer sh for the following reasons:\n\nit is standardized\nit is much simpler and easier to learn\nit is portable across POSIX systems — even if they happen not to have bash, they are required to have sh\n\nThere are advantages to using bash as well. Its features make programming more convenient and similar to programming in other modern programming languages. These include things like scoped local variables and arrays. Plain sh is a very minimalistic programming language."
  },
  {
    "question": "How to specify the private SSH-key to use when executing shell command on Git?",
    "answer": "None of these solutions worked for me.\nInstead, I elaborate on @Martin v. Löwis  's mention of setting a config file for SSH.\nSSH will look for the user's ~/.ssh/config file. I have mine setup as:\nHost gitserv\n    Hostname remote.server.com\n    IdentityFile ~/.ssh/id_rsa.github\n    IdentitiesOnly yes # see NOTES below\n    AddKeysToAgent yes\n\nAnd I add a remote git repository:\ngit remote add origin git@gitserv:myrepo.git\n\n(or clone a fresh copy of the repo with git@gitserv:myrepo.git as address)\nAnd then git commands work normally for me.\ngit push -v origin master\n\nIf you have submodules, you can also execute the following in the repo directory, to force the submodules to use the same key:\ngit config url.git@gitserv:.insteadOf https://remote.server.com\n\nNOTES\n\nThe IdentitiesOnly yes is required to prevent the SSH default behavior of sending the identity file matching the default filename for each protocol. If you have a file named ~/.ssh/id_rsa that will get tried BEFORE your ~/.ssh/id_rsa.github without this option.\n\nAddKeysToAgent yes lets you avoid reentering the key passphrase every time.\n\nYou can also add User git to avoid writing git@ every time.\n\n\nReferences\n\nBest way to use multiple SSH private keys on one client\nHow could I stop ssh offering a wrong key"
  },
  {
    "question": "How to convert a string to lower case in Bash",
    "answer": "There are various ways:\nPOSIX standard\ntr\n$ echo \"$a\" | tr '[:upper:]' '[:lower:]'\nhi all\n\nAWK\n$ echo \"$a\" | awk '{print tolower($0)}'\nhi all\n\nNon-POSIX\nYou may run into portability issues with the following examples:\nBash 4.0\n$ echo \"${a,,}\"\nhi all\n\nsed\n$ echo \"$a\" | sed -e 's/\\(.*\\)/\\L\\1/'\nhi all\n# this also works:\n$ sed -e 's/\\(.*\\)/\\L\\1/' <<< \"$a\"\nhi all\n\nPerl\n$ echo \"$a\" | perl -ne 'print lc'\nhi all\n\nBash\nlc(){\n    case \"$1\" in\n        [A-Z])\n        n=$(printf \"%d\" \"'$1\")\n        n=$((n+32))\n        printf \\\\$(printf \"%o\" \"$n\")\n        ;;\n        *)\n        printf \"%s\" \"$1\"\n        ;;\n    esac\n}\nword=\"I Love Bash\"\nfor((i=0;i<${#word};i++))\ndo\n    ch=\"${word:$i:1}\"\n    lc \"$ch\"\ndone\n\nNote: YMMV on this one. Doesn't work for me (GNU bash version 4.2.46 and 4.0.33 (and same behaviour 2.05b.0 but nocasematch  is not implemented)) even with using shopt -u nocasematch;. Unsetting that nocasematch causes [[ \"fooBaR\" == \"FOObar\" ]] to match OK BUT inside case weirdly [b-z] are incorrectly matched by [A-Z]. Bash is confused by the double-negative (\"unsetting nocasematch\")! :-)"
  },
  {
    "question": "YYYY-MM-DD format date in shell script",
    "answer": "In bash (>=4.2) it is preferable to use printf's built-in date formatter (part of bash) rather than the external date (usually GNU date). Note that invoking a subshell has performance problems in Cygwin due to a slow fork() call on Windows.\nAs such:\n# put current date as yyyy-mm-dd in $date\n# -1 -> explicit current date, bash >=4.3 defaults to current time if not provided\n# -2 -> start time for shell\nprintf -v date '%(%Y-%m-%d)T\\n' -1\n\n# put current date as yyyy-mm-dd HH:MM:SS in $date\nprintf -v date '%(%Y-%m-%d %H:%M:%S)T\\n' -1\n\n# to print directly remove -v flag, as such:\nprintf '%(%Y-%m-%d)T\\n' -1\n# -> current date printed to terminal\n\nIn bash (<4.2):\n# put current date as yyyy-mm-dd in $date\ndate=$(date '+%Y-%m-%d')\n\n# put current date as yyyy-mm-dd HH:MM:SS in $date\ndate=$(date '+%Y-%m-%d %H:%M:%S')\n\n# print current date directly\necho $(date '+%Y-%m-%d')\n\nOther available date formats can be viewed from the date man pages (for external non-bash specific command):\nman date"
  },
  {
    "question": "How can I declare and use Boolean variables in a shell script?",
    "answer": "Revised Answer (Feb 12, 2014)\nthe_world_is_flat=true\n# ...do something interesting...\nif [ \"$the_world_is_flat\" = true ] ; then\n    echo 'Be careful not to fall off!'\nfi\n\n\nOriginal Answer\nCaveats: https://stackoverflow.com/a/21210966/89391\nthe_world_is_flat=true\n# ...do something interesting...\nif $the_world_is_flat ; then\n    echo 'Be careful not to fall off!'\nfi\n\nFrom: Using boolean variables in Bash\nThe reason the original answer is included here is because the comments before the revision on Feb 12, 2014 pertain only to the original answer, and many of the comments are wrong when associated with the revised answer. For example, Dennis Williamson's comment about Bash's builtin true on Jun 2, 2010 only applies to the original answer, not the revised."
  },
  {
    "question": "Running shell command and capturing the output",
    "answer": "In all officially maintained versions of Python, the simplest approach is to use the subprocess.check_output function:\n>>> subprocess.check_output(['ls', '-l'])\nb'total 0\\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\\n'\n\ncheck_output runs a single program that takes only arguments as input.1 It returns the result exactly as printed to stdout. If you need to write input to stdin, skip ahead to the run or Popen sections. If you want to execute complex shell commands, see the note on shell=True at the end of this answer.\nThe check_output function works in all officially maintained versions of Python. But for more recent versions, a more flexible approach is available.\nModern versions of Python (3.5 or higher): run\nIf you're using Python 3.5+, and do not need backwards compatibility, the new run function is recommended by the official documentation for most tasks. It provides a very general, high-level API for the subprocess module. To capture the output of a program, pass the subprocess.PIPE flag to the stdout keyword argument. Then access the stdout attribute of the returned CompletedProcess object:\n>>> import subprocess\n>>> result = subprocess.run(['ls', '-l'], stdout=subprocess.PIPE)\n>>> result.stdout\nb'total 0\\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\\n'\n\nThe return value is a bytes object, so if you want a proper string, you'll need to decode it. Assuming the called process returns a UTF-8-encoded string:\n>>> result.stdout.decode('utf-8')\n'total 0\\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\\n'\n\nThis can all be compressed to a one-liner if desired:\n>>> subprocess.run(['ls', '-l'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n'total 0\\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\\n'\n\nIf you want to pass input to the process's stdin, you can pass a bytes object to the input keyword argument:\n>>> cmd = ['awk', 'length($0) > 5']\n>>> ip = 'foo\\nfoofoo\\n'.encode('utf-8')\n>>> result = subprocess.run(cmd, stdout=subprocess.PIPE, input=ip)\n>>> result.stdout.decode('utf-8')\n'foofoo\\n'\n\nYou can capture errors by passing stderr=subprocess.PIPE (capture to result.stderr) or stderr=subprocess.STDOUT (capture to result.stdout along with regular output). If you want run to throw an exception when the process returns a nonzero exit code, you can pass check=True. (Or you can check the returncode attribute of result above.) When security is not a concern, you can also run more complex shell commands by passing shell=True as described at the end of this answer.\nLater versions of Python streamline the above further. In Python 3.7+, the above one-liner can be spelled like this:\n>>> subprocess.run(['ls', '-l'], capture_output=True, text=True).stdout\n'total 0\\n-rw-r--r--  1 memyself  staff  0 Mar 14 11:04 files\\n'\n\nUsing run this way adds just a bit of complexity, compared to the old way of doing things. But now you can do almost anything you need to do with the run function alone.\nOlder versions of Python (3-3.4): more about check_output\nIf you are using an older version of Python, or need modest backwards compatibility, you can use the check_output function as briefly described above. It has been available since Python 2.7.\nsubprocess.check_output(*popenargs, **kwargs)  \n\nIt takes takes the same arguments as Popen (see below), and returns a string containing the program's output. The beginning of this answer has a more detailed usage example. In Python 3.5+, check_output is equivalent to executing run with check=True and stdout=PIPE, and returning just the stdout attribute.\nYou can pass stderr=subprocess.STDOUT to ensure that error messages are included in the returned output. When security is not a concern, you can also run more complex shell commands by passing shell=True as described at the end of this answer.\nIf you need to pipe from stderr or pass input to the process, check_output won't be up to the task. See the Popen examples below in that case.\nComplex applications and legacy versions of Python (2.6 and below): Popen\nIf you need deep backwards compatibility, or if you need more sophisticated functionality than check_output or run provide, you'll have to work directly with Popen objects, which encapsulate the low-level API for subprocesses.\nThe Popen constructor accepts either a single command without arguments, or a list containing a command as its first item, followed by any number of arguments, each as a separate item in the list. shlex.split can help parse strings into appropriately formatted lists. Popen objects also accept a host of different arguments for process IO management and low-level configuration.\nTo send input and capture output, communicate is almost always the preferred method. As in:\noutput = subprocess.Popen([\"mycmd\", \"myarg\"], \n                          stdout=subprocess.PIPE).communicate()[0]\n\nOr\n>>> import subprocess\n>>> p = subprocess.Popen(['ls', '-a'], stdout=subprocess.PIPE, \n...                                    stderr=subprocess.PIPE)\n>>> out, err = p.communicate()\n>>> print out\n.\n..\nfoo\n\nIf you set stdin=PIPE, communicate also allows you to pass data to the process via stdin:\n>>> cmd = ['awk', 'length($0) > 5']\n>>> p = subprocess.Popen(cmd, stdout=subprocess.PIPE,\n...                           stderr=subprocess.PIPE,\n...                           stdin=subprocess.PIPE)\n>>> out, err = p.communicate('foo\\nfoofoo\\n')\n>>> print out\nfoofoo\n\nNote Aaron Hall's answer, which indicates that on some systems, you may need to set stdout, stderr, and stdin all to PIPE (or DEVNULL) to get communicate to work at all.\nIn some rare cases, you may need complex, real-time output capturing. Vartec's answer suggests a way forward, but methods other than communicate are prone to deadlocks if not used carefully.\nAs with all the above functions, when security is not a concern, you can run more complex shell commands by passing shell=True.\nNotes\n1. Running shell commands: the shell=True argument\nNormally, each call to run, check_output, or the Popen constructor executes a single program. That means no fancy bash-style pipes. If you want to run complex shell commands, you can pass shell=True, which all three functions support. For example:\n>>> subprocess.check_output('cat books/* | wc', shell=True, text=True)\n' 1299377 17005208 101299376\\n'\n\nHowever, doing this raises security concerns. If you're doing anything more than light scripting, you might be better off calling each process separately, and passing the output from each as an input to the next, via\nrun(cmd, [stdout=etc...], input=other_output)\n\nOr\nPopen(cmd, [stdout=etc...]).communicate(other_output)\n\nThe temptation to directly connect pipes is strong; resist it. Otherwise, you'll likely see deadlocks or have to do hacky things like this."
  },
  {
    "question": "Assigning default values to shell variables with a single command in bash",
    "answer": "Very close to what you posted, actually. You can use something called Bash parameter expansion to accomplish this.\nTo get the assigned value, or default if it's missing:\nFOO=\"${VARIABLE:-default}\"  # FOO will be assigned 'default' value if VARIABLE not set or null.\n# The value of VARIABLE remains untouched.\n\nTo do the same, as well as assign default to VARIABLE:\nFOO=\"${VARIABLE:=default}\"  # If VARIABLE not set or null, set its value to 'default'. \n# Then that value will be assigned to FOO"
  },
  {
    "question": "Replace one substring for another string in shell script",
    "answer": "To replace the first occurrence of a pattern with a given string, use ${parameter/pattern/string}:\n#!/bin/bash\nfirstString=\"I love Suzi and Marry\"\nsecondString=\"Sara\"\necho \"${firstString/Suzi/\"$secondString\"}\"\n# prints 'I love Sara and Marry'\n\nTo replace all occurrences, use ${parameter//pattern/string}:\nmessage='The secret code is 12345'\necho \"${message//[0-9]/X}\"\n# prints 'The secret code is XXXXX'\n\n(This is documented in the Bash Reference Manual, §3.5.3 \"Shell Parameter Expansion\".)\nNote that this feature is not specified by POSIX — it's a Bash extension — so not all Unix shells implement it. For the relevant POSIX documentation, see The Open Group Technical Standard Base Specifications, Issue 7, the Shell & Utilities volume, §2.6.2 \"Parameter Expansion\"."
  },
  {
    "question": "How to use SSH to run a local shell script on a remote machine?",
    "answer": "If Machine A is a Windows box, you can use Plink (part of PuTTY) with the -m parameter, and it will execute the local script on the remote server.\n\nplink root@MachineB -m local_script.sh\n\n\nIf Machine A is a Unix-based system, you can use:\n\nssh root@MachineB 'bash -s' < local_script.sh\n\n\nYou shouldn't have to copy the script to the remote server to run it."
  },
  {
    "question": "Why do people write &quot;#!/usr/bin/env python&quot; on the first line of a Python script?",
    "answer": "If you have several versions of Python installed, /usr/bin/env will ensure the interpreter used is the first one on your environment's $PATH. The alternative would be to hard code something like #!/usr/bin/python; that's ok, but less flexible.\nIn Unix, an executable file that's meant to be interpreted can indicate what interpreter to use by having a #! at the start of the first line, followed by the interpreter (and any flags it may need).\nIf you're talking about other platforms, of course, this rule does not apply (but that \"shebang line\" does no harm, and will help if you ever copy that script to a platform with a Unix base, such as Linux, Mac, etc.)."
  },
  {
    "question": "How to echo shell commands as they are executed",
    "answer": "set -x or set -o xtrace expands variables and prints a little + sign before the line.\nset -v or set -o verbose does not expand the variables before printing.\nUse set +x and set +v to turn off the above settings.\nOn the first line of the script, one can put #!/bin/sh -x (or -v) to have the same effect as set -x (or -v) later in the script.\nThe above also works with /bin/sh.\nSee the bash-hackers' wiki on set attributes, and on debugging.\n$ cat shl\n#!/bin/bash                                                                     \n\nDIR=/tmp/so\nls $DIR\n\n$ bash -x shl \n+ DIR=/tmp/so\n+ ls /tmp/so\n$"
  },
  {
    "question": "Find all files containing a specific text (string) on Linux?",
    "answer": "Do the following:\ngrep -rnw '/path/to/somewhere/' -e 'pattern'\n\n\n-r or -R is recursive,\n-n is line number, and\n-w stands for match the whole word.\n-l (lower-case L) can be added to just give the file name of matching files.\n-e is the pattern used during the search\n\nAlong with these, --exclude, --include, --exclude-dir flags could be used for efficient searching:\n\nThis will only search through those files which have .c or .h extensions:\ngrep --include=\\*.{c,h} -rnw '/path/to/somewhere/' -e \"pattern\"\n\n\nThis will exclude searching all the files ending with .o extension:\ngrep --exclude=\\*.o -rnw '/path/to/somewhere/' -e \"pattern\"\n\n\nFor directories it's possible to exclude one or more directories using the --exclude-dir parameter. For example, this will exclude the dirs dir1/, dir2/ and all of them matching *.dst/:\ngrep --exclude-dir={dir1,dir2,*.dst} -rnw '/path/to/search/' -e \"pattern\"\n\n\n\nThis works very well for me, to achieve almost the same purpose like yours.\nFor more options, see man grep."
  },
  {
    "question": "How can I recursively find all files in current and subfolders based on wildcard matching?",
    "answer": "Use find:\nfind . -name \"foo*\"\n\nfind needs a starting point, so the . (dot) points to the current directory.\nIf you need case insensitive search use :\nfind . -iname \"foo*\""
  },
  {
    "question": "How to change the output color of echo in Linux",
    "answer": "You can use these ANSI escape codes:\nBlack        0;30     Dark Gray     1;30\nRed          0;31     Light Red     1;31\nGreen        0;32     Light Green   1;32\nBrown/Orange 0;33     Yellow        1;33\nBlue         0;34     Light Blue    1;34\nPurple       0;35     Light Purple  1;35\nCyan         0;36     Light Cyan    1;36\nLight Gray   0;37     White         1;37\n\nAnd then use them like this in your script:\n#    .---------- constant part!\n#    vvvv vvvv-- the code from above\nRED='\\033[0;31m'\nNC='\\033[0m' # No Color\nprintf \"I ${RED}love${NC} Stack Overflow\\n\"\n\nwhich prints love in red.\nFrom @james-lim's comment, if you are using the echo command, be sure to use the -e flag to allow backslash escapes.\n#    .---------- constant part!\n#    vvvv vvvv-- the code from above\nRED='\\033[0;31m'\nNC='\\033[0m' # No Color\necho -e \"I ${RED}love${NC} Stack Overflow\"\n\nNote: Don't add \"\\n\" when using echo unless you want to add an additional empty line."
  },
  {
    "question": "How do I delete an exported environment variable?",
    "answer": "unset is the command you're looking for.\nunset GNUPLOT_DRIVER_DIR"
  },
  {
    "question": "How do I exclude a directory when using `find`?",
    "answer": "If -prune doesn't work for you, this will:\nfind -name \"*.js\" -not -path \"./directory/*\"\n\nCaveat: requires traversing all of the unwanted directories."
  },
  {
    "question": "How can I symlink a file in Linux?",
    "answer": "To create a new symlink (will fail if symlink exists already):\nln -s /path/to/file /path/to/symlink\n\nTo create or update a symlink:\nln -sf /path/to/file /path/to/symlink"
  },
  {
    "question": "How do I recursively grep all directories and subdirectories?",
    "answer": "grep -r \"texthere\" .\n\n\nThe first parameter represents the regular expression to search for, while the second one represents the directory that should be searched. In this case, . means the current directory.\n\nNote: This works for GNU grep, and on some platforms like Solaris you must specifically use GNU grep as opposed to legacy implementation.  For Solaris this is the ggrep command."
  },
  {
    "question": "Looping through the content of a file in Bash",
    "answer": "One way to do it is:\n\nwhile read p; do\n  echo \"$p\"\ndone <peptides.txt\n\n\nAs pointed out in the comments, this has the side effects of trimming leading whitespace, interpreting backslash sequences, and skipping the last line if it's missing a terminating linefeed. If these are concerns, you can do:\n\nwhile IFS=\"\" read -r p || [ -n \"$p\" ]\ndo\n  printf '%s\\n' \"$p\"\ndone < peptides.txt\n\n\n\n\nExceptionally, if the loop body may read from standard input, you can open the file using a different file descriptor:\n\nwhile read -u 10 p; do\n  ...\ndone 10<peptides.txt\n\n\nHere, 10 is just an arbitrary number (different from 0, 1, 2)."
  },
  {
    "question": "How do I profile C++ code running on Linux?",
    "answer": "If your goal is to use a profiler, use one of the suggested ones.\nHowever, if you're in a hurry and you can manually interrupt your program under the debugger while it's being subjectively slow, there's a simple way to find performance problems.\nExecute your code in a debugger like gdb, halt it and each time look at the call stack (e.g. backtrace) several times. If there is some code that is wasting some percentage of the time, 20% or 50% or whatever, that is the probability that you will catch it in the act on each sample. So, that is roughly the percentage of samples on which you will see it. There is no educated guesswork required. If you do have a guess as to what the problem is, this will prove or disprove it.\nYou probably have multiple performance problems of different sizes. If you clean out any one of them, the remaining ones will take a larger percentage, and be easier to spot, on subsequent passes. This magnification effect, when compounded over multiple problems, can lead to truly massive speedup factors.\nCaveat: Programmers tend to be skeptical of this technique unless they've used it themselves. They will say that profilers give you this information, but that is only true if they sample the entire call stack, and then let you examine a random set of samples. (The summaries are where the insight is lost.) Call graphs don't give you the same information, because\n\nThey don't summarize at the instruction level, and\nThey give confusing summaries in the presence of recursion.\n\nThey will also say it only works on toy programs, when actually it works on any program, and it seems to work better on bigger programs, because they tend to have more problems to find. They will say it sometimes finds things that aren't problems, but that is only true if you see something once. If you see a problem on more than one sample, it is real.\nP.S. This can also be done on multi-thread programs if there is a way to collect call-stack samples of the thread pool at a point in time, as there is in Java.\nP.P.S As a rough generality, the more layers of abstraction you have in your software, the more likely you are to find that that is the cause of performance problems (and the opportunity to get speedup).\nAdded: It might not be obvious, but the stack sampling technique works equally well in the presence of recursion. The reason is that the time that would be saved by removal of an instruction is approximated by the fraction of samples containing it, regardless of the number of times it may occur within a sample.\nAnother objection I often hear is: \"It will stop someplace random, and it will miss the real problem\".\nThis comes from having a prior concept of what the real problem is.\nA key property of performance problems is that they defy expectations.\nSampling tells you something is a problem, and your first reaction is disbelief.\nThat is natural, but you can be sure if it finds a problem it is real, and vice-versa.\nAdded: Let me make a Bayesian explanation of how it works.  Suppose there is some instruction I (call or otherwise) which is on the call stack some fraction f of the time (and thus costs that much). For simplicity, suppose we don't know what f is, but assume it is either 0.1, 0.2, 0.3, ... 0.9, 1.0, and the prior probability of each of these possibilities is 0.1, so all of these costs are equally likely a-priori.\nThen suppose we take just 2 stack samples, and we see instruction I on both samples, designated observation o=2/2. This gives us new estimates of the frequency f of I, according to this:\nPrior\nP(f=x) x  P(o=2/2|f=x) P(o=2/2&&f=x)  P(o=2/2&&f >= x)  P(f >= x | o=2/2)\n\n0.1    1     1             0.1          0.1            0.25974026\n0.1    0.9   0.81          0.081        0.181          0.47012987\n0.1    0.8   0.64          0.064        0.245          0.636363636\n0.1    0.7   0.49          0.049        0.294          0.763636364\n0.1    0.6   0.36          0.036        0.33           0.857142857\n0.1    0.5   0.25          0.025        0.355          0.922077922\n0.1    0.4   0.16          0.016        0.371          0.963636364\n0.1    0.3   0.09          0.009        0.38           0.987012987\n0.1    0.2   0.04          0.004        0.384          0.997402597\n0.1    0.1   0.01          0.001        0.385          1\n\n                  P(o=2/2) 0.385\n\nThe last column says that, for example, the probability that f >= 0.5 is 92%, up from the prior assumption of 60%.\nSuppose the prior assumptions are different. Suppose we assume P(f=0.1) is .991 (nearly certain), and all the other possibilities are almost impossible (0.001). In other words, our prior certainty is that I is cheap. Then we get:\nPrior\nP(f=x) x  P(o=2/2|f=x) P(o=2/2&& f=x)  P(o=2/2&&f >= x)  P(f >= x | o=2/2)\n\n0.001  1    1              0.001        0.001          0.072727273\n0.001  0.9  0.81           0.00081      0.00181        0.131636364\n0.001  0.8  0.64           0.00064      0.00245        0.178181818\n0.001  0.7  0.49           0.00049      0.00294        0.213818182\n0.001  0.6  0.36           0.00036      0.0033         0.24\n0.001  0.5  0.25           0.00025      0.00355        0.258181818\n0.001  0.4  0.16           0.00016      0.00371        0.269818182\n0.001  0.3  0.09           0.00009      0.0038         0.276363636\n0.001  0.2  0.04           0.00004      0.00384        0.279272727\n0.991  0.1  0.01           0.00991      0.01375        1\n\n                  P(o=2/2) 0.01375\n\nNow it says P(f >= 0.5) is 26%, up from the prior assumption of 0.6%. So Bayes allows us to update our estimate of the probable cost of I. If the amount of data is small, it doesn't tell us accurately what the cost is, only that it is big enough to be worth fixing.\nYet another way to look at it is called the Rule Of Succession.\nIf you flip a coin 2 times, and it comes up heads both times, what does that tell you about the probable weighting of the coin?\nThe respected way to answer is to say that it's a Beta distribution, with average value (number of hits + 1) / (number of tries + 2) = (2+1)/(2+2) = 75%.\n(The key is that we see I more than once. If we only see it once, that doesn't tell us much except that f > 0.)\nSo, even a very small number of samples can tell us a lot about the cost of instructions that it sees. (And it will see them with a frequency, on average, proportional to their cost. If n samples are taken, and f is the cost, then I will appear on nf+/-sqrt(nf(1-f)) samples. Example, n=10, f=0.3, that is 3+/-1.4 samples.)\n\nAdded: To give an intuitive feel for the difference between measuring and random stack sampling:\nThere are profilers now that sample the stack, even on wall-clock time, but what comes out is measurements (or hot path, or hot spot, from which a \"bottleneck\" can easily hide). What they don't show you (and they easily could) is the actual samples themselves. And if your goal is to find the bottleneck, the number of them you need to see is, on average, 2 divided by the fraction of time it takes.\nSo if it takes 30% of time, 2/.3 = 6.7 samples, on average, will show it, and the chance that 20 samples will show it is 99.2%.\nHere is an off-the-cuff illustration of the difference between examining measurements and examining stack samples.\nThe bottleneck could be one big blob like this, or numerous small ones, it makes no difference.\n\nMeasurement is horizontal; it tells you what fraction of time specific routines take.\nSampling is vertical.\nIf there is any way to avoid what the whole program is doing at that moment, and if you see it on a second sample, you've found the bottleneck.\nThat's what makes the difference - seeing the whole reason for the time being spent, not just how much."
  },
  {
    "question": "How do I change permissions for a folder and its subfolders/files?",
    "answer": "The other answers are correct, in that chmod -R 755 will set these permissions to all files and subfolders in the tree. But why on earth would you want to? It might make sense for the directories, but why set the execute bit on all the files?\nI suspect what you really want to do is set the directories to 755 and either leave the files alone or set them to 644. For this, you can use the find command. For example:\nTo change all the directories to 755 (drwxr-xr-x):\nfind /opt/lampp/htdocs -type d -exec chmod 755 {} \\;\n\nTo change all the files to 644 (-rw-r--r--):\nfind /opt/lampp/htdocs -type f -exec chmod 644 {} \\;\n\nSome splainin': (thanks @tobbez)\n\nchmod 755 {} specifies the command that will be executed by find for each directory\nchmod 644 {} specifies the command that will be executed by find for each file\n{} is replaced by the path\n; the semicolon tells find that this is the end of the command it's supposed to execute\n\\; the semicolon is escaped, otherwise it would be interpreted by the shell instead of find"
  },
  {
    "question": "How do I prompt for Yes/No/Cancel input in a Linux shell script?",
    "answer": "A widely available method to get user input at a shell prompt is the read command. Here is a demonstration:\nwhile true; do\n    read -p \"Do you wish to install this program? \" yn\n    case $yn in\n        [Yy]* ) make install; break;;\n        [Nn]* ) exit;;\n        * ) echo \"Please answer yes or no.\";;\n    esac\ndone\n\n\nAnother method, pointed out by Steven Huwig, is Bash's select command. Here is the same example using select:\necho \"Do you wish to install this program?\"\nselect yn in \"Yes\" \"No\"; do\n    case $yn in\n        Yes ) make install; break;;\n        No ) exit;;\n    esac\ndone\n\nWith select you don't need to sanitize the input – it displays the available choices, and you type a number corresponding to your choice. It also loops automatically, so there's no need for a while true loop to retry if they give invalid input. If you want to allow more flexible input (accepting the words of the options, rather than just their number), you can alter it like this:\necho \"Do you wish to install this program?\"\nselect strictreply in \"Yes\" \"No\"; do\n    relaxedreply=${strictreply:-$REPLY}\n    case $relaxedreply in\n        Yes | yes | y ) make install; break;;\n        No  | no  | n ) exit;;\n    esac\ndone\n\n\nAlso, Léa Gris demonstrated a way to make the request language agnostic in her answer. Adapting my first example to better serve multiple languages might look like this:\nset -- $(locale LC_MESSAGES)\nyesexpr=\"$1\"; noexpr=\"$2\"; yesword=\"$3\"; noword=\"$4\"\n\nwhile true; do\n    read -p \"Install (${yesword} / ${noword})? \" yn\n    if [[ \"$yn\" =~ $yesexpr ]]; then make install; exit; fi\n    if [[ \"$yn\" =~ $noexpr ]]; then exit; fi\n    echo \"Answer ${yesword} / ${noword}.\"\ndone\n\nObviously other communication strings remain untranslated here (Install, Answer) which would need to be addressed in a more fully completed translation, but even a partial translation would be helpful in many cases.\n\nFinally, please check out the excellent answer by F. Hauri."
  },
  {
    "question": "What is &#39;:-!!&#39; in C?",
    "answer": "This is, in effect, a way to check whether the expression e can be evaluated to be 0, and if not, to fail the build.\n\nThe macro is somewhat misnamed; it should be something more like BUILD_BUG_OR_ZERO, rather than ...ON_ZERO. (There have been occasional discussions about whether this is a confusing name.)\n\nYou should read the expression like this:\n\nsizeof(struct { int: -!!(e); }))\n\n\n\n(e): Compute expression e.\n!!(e): Logically negate twice: 0 if e == 0; otherwise 1.\n-!!(e): Numerically negate the expression from step 2: 0 if it was 0; otherwise -1.\nstruct{int: -!!(0);} --> struct{int: 0;}: If it was zero, then we declare a struct with an anonymous integer bitfield that has width zero. Everything is fine and we proceed as normal.\nstruct{int: -!!(1);} --> struct{int: -1;}: On the other hand, if it isn't zero, then it will be some negative number. Declaring any bitfield with negative width is a compilation error.\n\n\nSo we'll either wind up with a bitfield that has width 0 in a struct, which is fine, or a bitfield with negative width, which is a compilation error. Then we take sizeof that field, so we get a size_t with the appropriate width (which will be zero in the case where e is zero).\n\n\n\nSome people have asked: Why not just use an assert?\n\nkeithmo's answer here has a good response:\n\n\n  These macros implement a compile-time test, while assert() is a run-time test.\n\n\nExactly right. You don't want to detect problems in your kernel at runtime that could have been caught earlier! It's a critical piece of the operating system. To whatever extent problems can be detected at compile time, so much the better."
  },
  {
    "question": "How to redirect output to a file and stdout",
    "answer": "The command you want is named tee:\n\nfoo | tee output.file\n\n\nFor example, if you only care about stdout:\n\nls -a | tee output.file\n\n\nIf you want to include stderr, do:\n\nprogram [arguments...] 2>&1 | tee outfile\n\n\n2>&1 redirects channel 2 (stderr/standard error) into channel 1 (stdout/standard output), such that both is written as stdout. It is also directed to the given output file as of the tee command.\n\nFurthermore, if you want to append to the log file, use tee -a as:\n\nprogram [arguments...] 2>&1 | tee -a outfile"
  },
  {
    "question": "Merge / convert multiple PDF files into one PDF",
    "answer": "Considering that pdfunite is part of poppler it has a higher chance to be installed, usage is also simpler than pdftk:\n⚠ IMPORTANT: Just make sure you remember to provide out.pdf, or else it will overwrite the last input file in your command ⚠\npdfunite in-1.pdf in-2.pdf in-n.pdf out.pdf\n\nA safer solution may include a test of non-existence\ntargeting the output file\nexport output_file=out.pdf && \\\n! test -e $output_file && \\\npdfunite in-1.pdf in-2.pdf in-n.pdf $output_file"
  },
  {
    "question": "How can I use grep to show just filenames on Linux?",
    "answer": "The standard option grep -l (that is a lowercase L) could do this.\n\nFrom the Unix standard:\n\n-l\n    (The letter ell.) Write only the names of files containing selected\n    lines to standard output. Pathnames are written once per file searched.\n    If the standard input is searched, a pathname of (standard input) will\n    be written, in the POSIX locale. In other locales, standard input may be\n    replaced by something more appropriate in those locales.\n\n\nYou also do not need -H in this case."
  },
  {
    "question": "How to kill a process running on particular port in Linux?",
    "answer": "This fuser 8080/tcp will print the PID of the process bound to that port.\nAnd this fuser -k 8080/tcp will kill that process.\nWorks on Linux only. More universal is use of lsof -i4 (or 6 for IPv6).\nGeneral form:\n# list the TCP process bound to port PORT\nfuser PORT/tcp\n# Example: list the TCP process bound to port 8080\nfuser 8080/tcp\n\n# list the UDP process bound to port PORT\nfuser PORT/udp\n# Example: list the UDP process bound to port 8080\nfuser 8080/udp"
  },
  {
    "question": "How do I create a copy of a directory in Unix/Linux?",
    "answer": "The option you're looking for is -R.\ncp -R path_to_source path_to_destination/\n\n\nIf destination doesn't exist, it will be created.\n-R means copy directories recursively. You can also use -r since it's case-insensitive.\nTo copy everything inside the source folder (symlinks, hidden files) without copying the source folder itself use -a flag along with trailing /. in the source (as per @muni764's / @Anton Krug's comment):\n\ncp -a path_to_source/. path_to_destination/"
  },
  {
    "question": "Count number of lines in a non binary file (Like a CSV or a TXT) file in terminal",
    "answer": "Use wc:\n\nwc -l <filename>\n\n\nThis will output the number of lines in <filename>:\n\n$ wc -l /dir/file.txt\n3272485 /dir/file.txt\n\n\nOr, to omit the <filename> from the result use wc -l < <filename>:\n\n$ wc -l < /dir/file.txt\n3272485\n\n\nYou can also pipe data to wc as well:\n\n$ cat /dir/file.txt | wc -l\n3272485\n$ curl yahoo.com --silent | wc -l\n63"
  },
  {
    "question": "Which version of PostgreSQL am I running?",
    "answer": "Run this query from PostgreSQL:\n\nSELECT version();"
  },
  {
    "question": "How can I close some specific port on Linux?",
    "answer": "Step 1:\nOpen up cmd.exe (note: you may need to run it as an administrator, but this isn't always necessary), then run the below command:\n\nnetstat -ano | findstr :<PORT>\n\n(Replace <PORT> with the port number you want, but keep the colon)\n\nThe area circled in red shows the PID (process identifier). Locate the PID of the process that's using the port you want.\nStep 2:\nNext, run the following command:\n\ntaskkill /PID <PID> /F\n\n(No colon this time)\n\nLastly, you can check whether the operation succeeded or not by re-running the command in \"Step 1\". If it was successful you shouldn't see any more search results for that port number."
  },
  {
    "question": "Pipe to/from the clipboard in a Bash script",
    "answer": "There are a wealth of clipboards you could be dealing with.  I expect you're probably a Linux user who wants to put stuff in the X Windows primary clipboard.  Usually, the clipboard you want to talk to has a utility that lets you talk to it.\nIn the case of X, there's xclip (and others). xclip -selection c will send data to the clipboard that works with Ctrl + C, Ctrl + V  in most applications.\nIf you're on Mac OS X, there's pbcopy. E.g., cat example.txt | pbcopy\nIf you're in Linux terminal mode (no X) then look into gpm or Screen which has a clipboard.  Try the Screen command readreg.\nUnder Windows 10+ or Cygwin, use /dev/clipboard or clip."
  },
  {
    "question": "Defining a variable with or without export",
    "answer": "export makes the variable available to sub-processes.\nThat is,\nexport name=value\n\nmeans that the variable name is available to any process you run from that shell process. If you want a process to make use of this variable, use export, and run the process from that shell.\nname=value\n\nmeans the variable scope is restricted to the shell, and is not available to any other process. You would use this for (say) loop variables, temporary variables etc. An important exception to this rule is that if you define the variable while running a command, that variable will be available to child processes. For example\nMY_VAR=yay node my-script.js\n\nIn this case MY_VAR will be available to the node process running my-script.\nIt's important to note that exporting a variable doesn't make it available to parent processes. That is, specifying and exporting a variable in a spawned process doesn't make it available in the process that launched it."
  },
  {
    "question": "Using ls to list directories and their total sizes",
    "answer": "Try something like:\n\ndu -sh *\n\n\nshort version of:\n\ndu --summarize --human-readable *\n\n\nExplanation:\n\ndu: Disk Usage\n\n-s: Display a summary for each specified file.  (Equivalent to -d 0)\n\n-h: \"Human-readable\" output.  Use unit suffixes: Byte, Kibibyte (KiB), Mebibyte (MiB), Gibibyte (GiB), Tebibyte (TiB) and Pebibyte (PiB). (BASE2)"
  },
  {
    "question": "Remove a symlink to a directory",
    "answer": "# this works:\nrm foo\n# versus this, which doesn't:\nrm foo/\n\nBasically, you need to tell it to delete a file, not delete a directory. I believe the difference between rm and rmdir exists because of differences in the way the C library treats each.\nAt any rate, the first should work, while the second should complain about foo being a directory.\nIf it doesn't work as above, then check your permissions. You need write permission to the containing directory to remove files."
  },
  {
    "question": "What does &#39;set -e&#39; mean in a Bash script?",
    "answer": "From help set and Bash Reference Documentation: The Set Builtin:\n  -e  Exit immediately if a command exits with a non-zero status.\n\nBut it's considered bad practice by some (Bash FAQ and IRC Freenode #bash FAQ authors). It's recommended to use:\ntrap 'do_something' ERR\n\nto run do_something function when errors occur.\nSee Why doesn't set -e (or set -o errexit, or trap ERR) do what I expected?"
  },
  {
    "question": "How can I exclude directories from grep -R?",
    "answer": "Recent versions of GNU Grep (>= 2.5.2) provide:\n--exclude-dir=dir\n\nwhich excludes directories matching the pattern dir from recursive directory searches.\nSo you can do:\ngrep -R --exclude-dir=node_modules 'some pattern' /path/to/search\n\nFor a bit more information regarding syntax and usage see\n\nThe GNU man page for File and Directory Selection\nA related StackOverflow answer Use grep --exclude/--include syntax to not grep through certain files\n\nFor older GNU Greps and POSIX Grep, use find as suggested in other answers.\nOr just use ack (Edit: or The Silver Searcher) and be done with it!"
  },
  {
    "question": "How do I use sudo to redirect output to a location I don&#39;t have permission to write to?",
    "answer": "Your command does not work because the redirection is performed by your shell which does not have the permission to write to /root/test.out. The redirection of the output is not performed by sudo.\n\nThere are multiple solutions:\n\n\nRun a shell with sudo and give the command to it by using the -c option:\n\nsudo sh -c 'ls -hal /root/ > /root/test.out'\n\nCreate a script with your commands and run that script with sudo:\n\n#!/bin/sh\nls -hal /root/ > /root/test.out\n\n\nRun sudo ls.sh. See Steve Bennett's answer if you don't want to create a temporary file.\nLaunch a shell with sudo -s then run your commands:\n\n[nobody@so]$ sudo -s\n[root@so]# ls -hal /root/ > /root/test.out\n[root@so]# ^D\n[nobody@so]$\n\nUse sudo tee (if you have to escape a lot when using the -c option):\n\nsudo ls -hal /root/ | sudo tee /root/test.out > /dev/null\n\n\nThe redirect to /dev/null is needed to stop tee from outputting to the screen. To append instead of overwriting the output file \n(>>), use tee -a or tee --append (the last one is specific to GNU coreutils).\n\n\nThanks go to Jd, Adam J. Forster and Johnathan for the second, third and fourth solutions."
  },
  {
    "question": "Shell command to tar directory excluding certain files/folders",
    "answer": "You can have multiple exclude options for tar so\n\n$ tar --exclude='./folder' --exclude='./upload/folder2' -zcvf /backup/filename.tgz .\n\n\netc will work. Make sure to put --exclude before the source and destination items."
  },
  {
    "question": "Recursively counting files in a Linux directory",
    "answer": "This should work:\n\nfind DIR_NAME -type f | wc -l\n\n\nExplanation:\n\n\n-type f to include only files.\n| (and not ¦) redirects find command's standard output to wc command's standard input.\nwc (short for word count) counts newlines, words and bytes on its input (docs).\n-l to count just newlines.\n\n\nNotes: \n\n\nReplace DIR_NAME with . to execute the command in the current folder.\nYou can also remove the -type f to include directories (and symlinks) in the count.\nIt's possible this command will overcount if filenames can contain newline characters.\n\n\nExplanation of why your example does not work:\n\nIn the command you showed, you do not use the \"Pipe\" (|) to kind-of connect two commands, but the broken bar (¦) which the shell does not recognize as a command or something similar. That's why you get that error message."
  },
  {
    "question": "Exploring Docker container&#39;s file system",
    "answer": "Here are a couple different methods...\nA) Use docker exec (easiest)\nDocker version 1.3 or newer supports the command exec that behave similar to nsenter. This command can run new process in already running container (container must have PID 1 process running already). You can run /bin/bash to explore container state:\ndocker exec -t -i mycontainer /bin/bash\n\nsee Docker command line documentation\nB) Use Snapshotting\nYou can evaluate container filesystem this way:\n\n# find ID of your running container:\ndocker ps\n\n# create image (snapshot) from container filesystem\ndocker commit 12345678904b5 mysnapshot\n\n# explore this filesystem using bash (for example)\ndocker run -t -i mysnapshot /bin/bash\n\nThis way, you can evaluate filesystem of the running container in the precise time moment. Container is still running, no future changes are included.\nYou can later delete snapshot using (filesystem of the running container is not affected!):\ndocker rmi mysnapshot\n\nC) Use ssh\nIf you need continuous access, you can install sshd to your container and run the sshd daemon:\ndocker run -d -p 22 mysnapshot /usr/sbin/sshd -D\n \n# you need to find out which port to connect:\ndocker ps\n\nThis way, you can run your app using ssh (connect and execute what you want).\nD) Use nsenter\nUse nsenter, see Why you don't need to run SSHd in your Docker containers\n\nThe short version is: with nsenter, you can get a shell into an\nexisting container, even if that container doesn’t run SSH or any kind\nof special-purpose daemon"
  },
  {
    "question": "How do I execute a program or call a system command?",
    "answer": "Use subprocess.run:\nimport subprocess\n\nsubprocess.run([\"ls\", \"-l\"]) \n\nAnother common way is os.system but you shouldn't use it because it is unsafe if any parts of the command come from outside your program or can contain spaces or other special characters, also subprocess.run is generally more flexible (you can get the stdout, stderr, the \"real\" status code, better error handling, etc.). Even the documentation for os.system recommends using subprocess instead.\nOn Python 3.4 and earlier, use subprocess.call instead of .run:\nsubprocess.call([\"ls\", \"-l\"])"
  },
  {
    "question": "Git is not working after macOS update (&quot;xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools&quot;)",
    "answer": "The problem is that Xcode Command-line Tools needs to be updated due to a MacOs update.\n\nDid not run into this on Sonoma.\n\nMaybe Apple fixed the process?\n\n\nUpdated for Ventura\n\nAfter opening the terminal after restarting, I tried to go to my code, and do a git status, and I got an error and prompt for command line software agreement:\nSo press space until you get to the [agree, print, cancel] option, so careful hit space to scroll down to the end, if you blow past It you have to run a command to get it back. Use sudo xcodebuild -license to get to it again.\nJust be careful on scrolling down and enter agree and press return and it will launch into an update.\n\nThen I tried to use git after the install, and it prompted me to install Xcode tools again.\nI followed my own advice from previous years (see below), and went to https://developer.apple.com/download/all and downloaded\n\"Command Line Tools for Xcode 14\" (You have to log in with your Apple ID and enter MFA code, so have all the devices you need for that handy. Then select \"Command Line Tools for Xcode 14\", or if you want to get into the alphas or betas, that's up to you. But stable releases are probably the best choice for software developers.\n\nYou have to either download the tools from CLI or the developer page and before you can use git, you need to reboot!!! Or you will get stuck in a loop of prompt & downloading\nRebooting will break the loop and complete the installation of your CLI tools including git so that you can get back to work\nSolutions for previous years, these may or may not be valid these days as the downloads page has changed significantly:\nPREVIOUS YEARS SOLUTIONS, probably #2 is most helpful.\n*** Solution #1:\nGo back to your terminal and enter:\nxcode-select --install\n\nYou'll then receive the following output:\nxcode-select: note: install requested for command line developer tools\n\nYou will then be prompted in a window to update Xcode Command Line tools. (which could take a while)\nOpen a new terminal window and your development tools should be returned.\nAddition: With any major or semi-major update you'll need to update the command line tools in order to get them functioning properly again. Check Xcode with any update. This goes beyond Mojave...\nAfter that restart your terminal\nAlternatively, IF that fails, and it might.... you'll get a pop-up box saying \"Software not found on server\", proceed to solution 2.\n*** Solution #2: (Preferred method)\nIf you hit xcode-select --install and it doesn't find the software, log into Apple Developer, and install it via webpage.\nLog in or sign up here:\nhttps://developer.apple.com/download/more/\nLook for: \"Command Line Tools for Xcode 14.x\" in the list of downloads\nThen click the dmg and download. (See previous image above) either way, you will probably wind up at an apple downloads webpage."
  },
  {
    "question": "How do I print colored text to the terminal?",
    "answer": "This somewhat depends on what platform you are on. The most common way to do this is by printing ANSI escape sequences. For a simple example, here's some Python code from the Blender build scripts:\nclass bcolors:\n    HEADER = '\\033[95m'\n    OKBLUE = '\\033[94m'\n    OKCYAN = '\\033[96m'\n    OKGREEN = '\\033[92m'\n    WARNING = '\\033[93m'\n    FAIL = '\\033[91m'\n    ENDC = '\\033[0m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n\nTo use code like this, you can do something like:\nprint(bcolors.WARNING + \"Warning: No active frommets remain. Continue?\" + bcolors.ENDC)\n\nOr, with Python 3.6+:\nprint(f\"{bcolors.WARNING}Warning: No active frommets remain. Continue?{bcolors.ENDC}\")\n\nThis will work on unixes including OS X, Linux and Windows (provided you use ANSICON, or in Windows 10 provided you enable VT100 emulation). There are ANSI codes for setting the color, moving the cursor, and more.\nIf you are going to get complicated with this (and it sounds like you are if you are writing a game), you should look into the \"curses\" module, which handles a lot of the complicated parts of this for you. The Python Curses HowTO is a good introduction.\nIf you are not using extended ASCII (i.e., not on a PC), you are stuck with the ASCII characters below 127, and '#' or '@' is probably your best bet for a block. If you can ensure your terminal is using a IBM extended ASCII character set, you have many more options. Characters 176, 177, 178 and 219 are the \"block characters\".\nSome modern text-based programs, such as \"Dwarf Fortress\", emulate text mode in a graphical mode, and use images of the classic PC font. You can find some of these bitmaps that you can use on the Dwarf Fortress Wiki see (user-made tilesets).\nThe Text Mode Demo Contest has more resources for doing graphics in text mode."
  },
  {
    "question": "How to reload .bashrc settings without logging out and back in again?",
    "answer": "You can enter the long form command:\nsource ~/.bashrc\n\nor you can use the shorter version of the command:\n. ~/.bashrc"
  },
  {
    "question": "How do I clear/delete the current line in terminal?",
    "answer": "You can use Ctrl+U to clear up to the beginning.\n\nYou can use Ctrl+W to delete just a word.\n\nYou can also use Ctrl+C to cancel.\n\nIf you want to keep the history, you can use Alt+Shift+# to make it a comment.\n\n\n\nBash Emacs Editing Mode Cheat Sheet"
  },
  {
    "question": "How can I get the current date and time in the terminal and set a custom command in the terminal for it?",
    "answer": "The command is date\n\nTo customise the output there are a myriad of options available, see date --help for a list.\n\nFor example, date '+%A %W %Y %X' gives Tuesday 34 2013 08:04:22 which is the name of the day of the week, the week number, the year and the time."
  },
  {
    "question": "How to move the cursor word by word in the OS X Terminal",
    "answer": "Out of the box you can use the quite bizarre Esc+F to move to the beginning of the next word and Esc+B to move to the beginning of the current word."
  },
  {
    "question": "How can I copy the output of a command directly into my clipboard?",
    "answer": "One way of doing it follows:\n\nInstall xclip, such as:\nsudo apt-get install xclip\n\nPipe the output into xclip to be copied into the clipboard:\ncat file | xclip\n\nPaste the text you just copied into a X application:\nxclip -o\n\n\nTo paste somewhere else other than an X application, such as a text area of a web page in a browser window, use:\ncat file | xclip -selection clipboard\n\nConsider creating an alias:\nalias \"c=xclip\"\nalias \"v=xclip -o\"\n\nTo see how useful this is, imagine I want to open my current path in a new terminal window (there may be other ways of doing it like Ctrl+T on some systems, but this is just for illustration purposes):\nTerminal 1:\npwd | c\n\nTerminal 2:\ncd `v`\n\nNotice the ` `  around v. This executes v as a command first and then substitutes it in-place for cd to use.\nOnly copy the content to the X clipboard\ncat file | xclip"
  },
  {
    "question": "Run / Open VSCode from Mac Terminal",
    "answer": "According to the docs on Launching from the command line:\n\nOpen Visual Studio Code\nOpen the command pallette with Command + Shift + P (or F1)\nType Shell in command palette\nSelect Shell Command: Install code in PATH from suggested list\n\n\nThat's it.\nNow open your terminal type.\n$ code .\n\n\nTo make this change persist after restart on MacOS\nMany Mac users find this is forgotten and needs to be re-applied after any restart. This may happen if MacOS has applied the quarantine attribute to VS Code, which the OS uses for the \"Are you sure?\" notice applied on first using apps downloaded from the internet.\nTo check if this attribute is applied, look for com.apple.quarantine in the list returned by this command (changing the path if that's not where you installed it):\nxattr \"/Applications/Visual Studio Code.app\"\n\nIf that does return com.apple.quarantine, you can remove the attribute using the same command with the -d flag (alongside -r to recursively remove it from all contained files and sudo to allow the change):\nsudo xattr -r -d com.apple.quarantine \"/Applications/Visual Studio Code.app\"\n\n...then do Shell Command : Install code in PATH as above after the attribute has been removed, and it should persist after restart.\nCredit: derflounder.wordpress.com article linked to by RicardoVallejo in this comment."
  },
  {
    "question": "Git branch command behaves like &#39;less&#39;",
    "answer": "As mentioned in comments to Mark Adelsberger's answer, this was a default behavior change introduced in Git 2.16.\n\nYou can turn paged output for git branch back off by default with the pager.branch config setting:\n\ngit config --global pager.branch false"
  },
  {
    "question": "Node Version Manager install - nvm command not found",
    "answer": "I think you missed this step:\nsource ~/.nvm/nvm.sh\n\nYou can run this command on the bash OR you can put it in the file /.bashrc or ~/.profile or ~/.zshrc to automatically load it\nhttps://github.com/creationix/nvm"
  },
  {
    "question": "Find and kill a process in one line using bash and regex",
    "answer": "In bash, using only the basic tools listed in your question(1), you should be able to do:\nkill $(ps aux | grep '[p]ython csp_build.py' | awk '{print $2}')\n\nDetails on its workings are as follows:\n\nThe ps gives you the list of all the processes.\nThe grep filters that based on your search string, [p] is a trick to stop you picking up the actual grep process itself.\nThe awk just gives you the second field of each line, which is the PID.\nThe $(x) construct means to execute x then take its output and put it on the command line. The output of that ps pipeline inside that construct above is the list of process IDs so you end up with a command like kill 1234 1122 7654.\n\nHere's a transcript showing it in action:\npax> sleep 3600 &\n[1] 2225\npax> sleep 3600 &\n[2] 2226\npax> sleep 3600 &\n[3] 2227\npax> sleep 3600 &\n[4] 2228\npax> sleep 3600 &\n[5] 2229\npax> kill $(ps aux | grep '[s]leep' | awk '{print $2}')\n[5]+  Terminated              sleep 3600\n[1]   Terminated              sleep 3600\n[2]   Terminated              sleep 3600\n[3]-  Terminated              sleep 3600\n[4]+  Terminated              sleep 3600\n\nand you can see it terminating all the sleepers.\nExplaining the grep '[p]ython csp_build.py' bit in a bit more detail: when you do sleep 3600 & followed by ps -ef | grep sleep, you tend to get two processes with sleep in it, the sleep 3600 and the grep sleep (because they both have sleep in them, that's not rocket science).\nHowever, ps -ef | grep '[s]leep' won't create a grep process with sleep in it, it instead creates one with the command grep '[s]leep' and here's the tricky bit: the grep doesn't find that one, because it's looking for the regular expression \"any character from the character class [s] (which is basically just s) followed by leep.\nIn other words, it's looking for sleep but the grep process is grep '[s]leep' which doesn't have the text sleep in it.\nWhen I was shown this (by someone here on SO), I immediately started using it because\n\nit's one less process than adding | grep -v grep; and\nit's elegant and sneaky, a rare combination :-)\n\n\n(1) If you're not limited to using those basic tools, there's a nifty pgrep command which will find processes based on certain criteria (assuming you have it available on your system, of course).\nFor example, you can use pgrep sleep to output the process IDs for all sleep commands (by default, it matches the process name). If you want to match the entire command line as shown in ps, you can do something like pgrep -f 'sleep 9999'.\nAs an aside, it doesn't list itself if you do pgrep pgrep, so the tricky filter method shown above is not necessary in this case.\nYou can check that the processes are the ones you're interested in by using -a to show the full process names. You can also limit the scope to your own processes (or a specific set of users) with -u or -U. See the man page for pgrep/pkill for more options.\nOnce you're satisfied it will only show the processes you're interested in, you can then use pkill with the same parameters to send a signal to all those processes."
  },
  {
    "question": "psql: FATAL: role &quot;postgres&quot; does not exist",
    "answer": "NOTE: If you installed postgres using homebrew, see the comments from @user3402754 and @originalhat below.\nNote that the error message does NOT talk about a missing database, it talks about a missing role. Later in the login process it might also stumble over the missing database.\nBut the first step is to check the missing role: What is the output within psql of the command \\du ? On my Ubuntu system the relevant line looks like this:\n                              List of roles\n Role name |            Attributes             | Member of \n-----------+-----------------------------------+-----------\n postgres  | Superuser, Create role, Create DB | {}        \n\nIf there is not at least one role with superuser, then you have a problem :-)\nIf there is one, you can use that to login. And looking at the output of your \\l command: The permissions for user on the template0 and template1 databases are the same as on my Ubuntu system for the superuser postgres. So I think your setup simple uses user as the superuser. So you could try this command to login:\nsudo -u user psql user\n\nIf user is really the DB superuser you can create another DB superuser and a private, empty database for him:\nCREATE USER postgres SUPERUSER;\nCREATE DATABASE postgres WITH OWNER postgres;\n\nBut since your postgres.app setup does not seem to do this, you also should not. Simple adapt the tutorial."
  },
  {
    "question": "How do I see which version of Swift I&#39;m using?",
    "answer": "What I do is say in the Terminal:\n\n$ xcrun swift -version\n\n\nOutput for Xcode 6.3.2 is:\n\nApple Swift version 1.2 (swiftlang-602.0.53.1 clang-602.0.53)\n\n\nOf course that assumes that your xcrun is pointing at your copy of Xcode correctly. If, like me, you're juggling several versions of Xcode, that can be a worry! To make sure that it is, say\n\n$ xcrun --find swift\n\n\nand look at the path to Xcode that it shows you. For example:\n\n/Applications/Xcode.app/...\n\n\nIf that's your Xcode, then the output from -version is accurate. If you need to repoint xcrun, use the Command Line Tools pop-up menu in Xcode's Locations preference pane."
  },
  {
    "question": "How to use &#39;cp&#39; command to exclude a specific directory?",
    "answer": "rsync is fast and easy:\nrsync -av --progress sourcefolder /destinationfolder --exclude thefoldertoexclude\n\nYou can use --exclude multiples times.\nrsync -av --progress sourcefolder /destinationfolder --exclude thefoldertoexclude --exclude anotherfoldertoexclude\n\nNote that the dir thefoldertoexclude after --exclude option is relative to the sourcefolder, i.e., sourcefolder/thefoldertoexclude.\nAlso you can add -n for dry run to see what will be copied before performing  real operation, and if everything is ok, remove -n from command line."
  },
  {
    "question": "Open terminal here in Mac OS finder",
    "answer": "As of Mac OS X Lion 10.7, Terminal includes exactly this functionality as a Service. As with most Services, these are disabled by default, so you'll need to enable this to make it appear in the Services menu.\n\n\n  System Preferences > Keyboard > Shortcuts > Services\n\n\nEnable New Terminal at Folder. There's also New Terminal Tab at Folder, which will create a tab in the frontmost Terminal window (if any, else it will create a new window). These Services work in all applications, not just Finder, and they operate on folders as well as absolute pathnames selected in text.\n\nYou can even assign command keys to them.\n\nServices appear in the Services submenu of each application menu, and within the contextual menu (Control-Click or Right-Click on a folder or pathname).\n\nThe New Terminal at Folder service will become active when you select a folder in Finder. You cannot simply have the folder open and run the service \"in place\". Go back to the parent folder, select the relevant folder, then activate the service via the Services menu or context menu.\n\nIn addition, Lion Terminal will open a new terminal window if you drag a folder (or pathname) onto the Terminal application icon, and you can also drag to the tab bar of an existing window to create a new tab.\n\nFinally, if you drag a folder or pathname onto a tab (in the tab bar) and the foreground process is the shell, it will automatically execute a \"cd\" command. (Dragging into the terminal view within the tab merely inserts the pathname on its own, as in older versions of Terminal.)\n\nYou can also do this from the command line or a shell script:\n\nopen -a Terminal /path/to/folder\n\n\nThis is the command-line equivalent of dragging a folder/pathname onto the Terminal application icon.\n\nOn a related note, Lion Terminal also has new Services for looking up man pages: Open man page in Terminal displays the selected man page topic in a new terminal window, and Search man Pages in Terminal performs \"apropos\" on the selected text. The former also understands man page references (\"open(2)\"), man page command line arguments (\"2 open\") and man page URLs (\"x-man-page://2/open\")."
  },
  {
    "question": "List Git aliases",
    "answer": "You can use --get-regexp with the regular expression ^alias, ie all configurations that start with alias\ngit config --get-regexp ^alias"
  },
  {
    "question": "List of ANSI color escape sequences",
    "answer": "The ANSI escape sequences you're looking for are the Select Graphic Rendition subset. All of these have the form\n\\033[XXXm\n\nwhere XXX is a series of semicolon-separated parameters.\nTo say, make text red, bold, and underlined (we'll discuss many other options below) in C you might write:\nprintf(\"\\033[31;1;4mHello\\033[0m\");\n\nIn C++ you'd use\nstd::cout<<\"\\033[31;1;4mHello\\033[0m\";\n\nIn Python3 you'd use\nprint(\"\\033[31;1;4mHello\\033[0m\")\n\nand in Bash you'd use\necho -e \"\\033[31;1;4mHello\\033[0m\"\n\nwhere the first part makes the text red (31), bold (1), underlined (4) and the last part clears all this (0).\nAs described in the table below, there are a large number of text properties you can set, such as boldness, font, underlining, &c.\nFont Effects\n\n\n\nCode\nEffect\nNote\n\n\n\n\n0\nReset / Normal\nall attributes off\n\n\n1\nBold or increased intensity\n\n\n\n2\nFaint (decreased intensity)\nNot widely supported.\n\n\n3\nItalic\nNot widely supported. Sometimes treated as inverse.\n\n\n4\nUnderline\n\n\n\n5\nSlow Blink\nless than 150 per minute\n\n\n6\nRapid Blink\nMS-DOS ANSI.SYS; 150+ per minute; not widely supported\n\n\n7\n[[reverse video]]\nswap foreground and background colors\n\n\n8\nConceal\nNot widely supported.\n\n\n9\nCrossed-out\nCharacters legible, but marked for deletion.  Not widely supported.\n\n\n10\nPrimary(default) font\n\n\n\n11–19\nAlternate font\nSelect alternate font n-10\n\n\n20\nFraktur\nhardly ever supported\n\n\n21\nBold off or Double Underline\nBold off not widely supported; double underline hardly ever supported.\n\n\n22\nNormal color or intensity\nNeither bold nor faint\n\n\n23\nNot italic, not Fraktur\n\n\n\n24\nUnderline off\nNot singly or doubly underlined\n\n\n25\nBlink off\n\n\n\n27\nInverse off\n\n\n\n28\nReveal\nconceal off\n\n\n29\nNot crossed out\n\n\n\n30–37\nSet foreground color\nSee color table below\n\n\n38\nSet foreground color\nNext arguments are 5;<n> or 2;<r>;<g>;<b>, see below\n\n\n39\nDefault foreground color\nimplementation defined (according to standard)\n\n\n40–47\nSet background color\nSee color table below\n\n\n48\nSet background color\nNext arguments are 5;<n> or 2;<r>;<g>;<b>, see below\n\n\n49\nDefault background color\nimplementation defined (according to standard)\n\n\n51\nFramed\n\n\n\n52\nEncircled\n\n\n\n53\nOverlined\n\n\n\n54\nNot framed or encircled\n\n\n\n55\nNot overlined\n\n\n\n60\nideogram underline\nhardly ever supported\n\n\n61\nideogram double underline\nhardly ever supported\n\n\n62\nideogram overline\nhardly ever supported\n\n\n63\nideogram double overline\nhardly ever supported\n\n\n64\nideogram stress marking\nhardly ever supported\n\n\n65\nideogram attributes off\nreset the effects of all of 60-64\n\n\n90–97\nSet bright foreground color\naixterm (not in standard)\n\n\n100–107\nSet bright background color\naixterm (not in standard)\n\n\n\n2-bit Colours\nYou've got this already!\n4-bit Colours\nThe standards implementing terminal colours began with limited (4-bit) options. The table below lists the RGB values of the background and foreground colours used for these by a variety of terminal emulators:\n\nUsing the above, you can make red text on a green background (but why?) using:\n\\033[31;42m\n\n11 Colours (An Interlude)\nIn their book \"Basic Color Terms: Their Universality and Evolution\", Brent Berlin and Paul Kay used data collected from twenty different languages from a range of language families to identify eleven possible basic color categories: white, black, red, green, yellow, blue, brown, purple, pink, orange, and gray.\nBerlin and Kay found that, in languages with fewer than the maximum eleven color categories, the colors followed a specific evolutionary pattern. This pattern is as follows:\n\nAll languages contain terms for black (cool colours) and white (bright colours).\nIf a language contains three terms, then it contains a term for red.\nIf a language contains four terms, then it contains a term for either green or yellow (but not both).\nIf a language contains five terms, then it contains terms for both green and yellow.\nIf a language contains six terms, then it contains a term for blue.\nIf a language contains seven terms, then it contains a term for brown.\nIf a language contains eight or more terms, then it contains terms for purple, pink, orange or gray.\n\nThis may be why story Beowulf only contains the colours black, white, and red. Homer's Odyssey contains black almost 200 times and white about 100 times. Red appears 15 times, while yellow and green appear only 10 times. (More information here)\nDifferences between languages are also interesting: note the profusion of distinct colour words used by English vs. Chinese. However, digging deeper into these languages shows that each uses colour in distinct ways. (More information)\n\nGenerally speaking, the naming, use, and grouping of colours in human languages is fascinating. Now, back to the show.\n8-bit (256) colours\nTechnology advanced, and tables of 256 pre-selected colours became available, as shown below.\n\nUsing these above, you can make pink text like so:\n\\033[38;5;206m     #That is, \\033[38;5;<FG COLOR>m\n\nAnd make an early-morning blue background using\n\\033[48;5;57m      #That is, \\033[48;5;<BG COLOR>m\n\nAnd, of course, you can combine these:\n\\033[38;5;206;48;5;57m\n\nThe 8-bit colours are arranged like so:\n\n\n\nRange\nDescription\n\n\n\n\n0x00-0x07\nstandard colors (same as the 4-bit colours)\n\n\n0x08-0x0F\nhigh intensity colors\n\n\n0x10-0xE7\n6 × 6 × 6 cube (216 colors): 16 + 36 × r + 6 × g + b (0 ≤ r, g, b ≤ 5)\n\n\n0xE8-0xFF\ngrayscale from black to white in 24 steps\n\n\n\nALL THE COLOURS\nNow we are living in the future, and the full RGB spectrum is available using:\n\\033[38;2;<r>;<g>;<b>m     #Select RGB foreground color\n\\033[48;2;<r>;<g>;<b>m     #Select RGB background color\n\nSo you can put pinkish text on a brownish background using\n\\033[38;2;255;82;197;48;2;155;106;0mHello\n\nSupport for \"true color\" terminals is listed here.\nMuch of the above is drawn from the Wikipedia page \"ANSI escape code\".\nA Handy Script to Remind Yourself\nSince I'm often in the position of trying to remember what colours are what, I have a handy script called: ~/bin/ansi_colours:\n#!/usr/bin/env python3\n\nfor i in range(30, 37 + 1):\n    print(\"\\033[%dm%d\\t\\t\\033[%dm%d\" % (i, i, i + 60, i + 60))\n\nprint(\"\\033[39m\\\\033[49m                 - Reset color\")\nprint(\"\\\\033[2K                          - Clear Line\")\nprint(\"\\\\033[<L>;<C>H or \\\\033[<L>;<C>f  - Put the cursor at line L and column C.\")\nprint(\"\\\\033[<N>A                        - Move the cursor up N lines\")\nprint(\"\\\\033[<N>B                        - Move the cursor down N lines\")\nprint(\"\\\\033[<N>C                        - Move the cursor forward N columns\")\nprint(\"\\\\033[<N>D                        - Move the cursor backward N columns\\n\")\nprint(\"\\\\033[2J                          - Clear the screen, move to (0,0)\")\nprint(\"\\\\033[K                           - Erase to end of line\")\nprint(\"\\\\033[s                           - Save cursor position\")\nprint(\"\\\\033[u                           - Restore cursor position\\n\")\nprint(\"\\\\033[4m                          - Underline on\")\nprint(\"\\\\033[24m                         - Underline off\\n\")\nprint(\"\\\\033[1m                          - Bold on\")\nprint(\"\\\\033[21m                         - Bold off\")\n\nThis prints"
  },
  {
    "question": "Open Sublime Text from Terminal in macOS",
    "answer": "I finally got this to work on my OSX box. I used these steps to get it to work:\n\nTest subl from your ST installation:\nFirst, navigate to a small folder in Terminal that you want ST to open and enter the following command:\n /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl .\n\nNOTE: You may need to replace Sublime\\ Text.app in the command above to Sublime\\ Text\\ 3.app or Sublime\\ Text\\ 2.app depending upon where the application is stored in your Applications directory. The . at the end of the above command opens the current working directory you are located in (again make sure you're in a directory that only contains a few files!).\nIf you DO NOT get Sublime Text opening your current working directory then the next set of steps will NOT work. If nothing happens or you get an error from Terminal it will be because it couldn't find the Sublime Text application. This would mean that you would have to check what you've typed (spelling, etc.) OR that Sublime Text isn't installed!\n\nCheck \".bash_profile\":\nNow it's time to create your symbolic link in your PATH folder, BUT, before we do, let's check your profile file by using nano ~/.bash_profile. These are the following lines that pertain to having subl work on the command line for Sublime Text:\n export PATH=/bin:/sbin:/usr/bin:/usr/local/sbin:/usr/local/bin:$PATH\n export EDITOR='subl -w'\n\nThe first line sets the location where you want Terminal to look for binaries on your machine, I'm going to store my symbolic link in the /usr/local/bin directory - I guess you could store it anywhere provided you've notified Terminal where to look for binaries.\nThe second line is OPTIONAL and just sets Sublime Text as the default editor. The flag -w has been added and you can find out more about flags by going to the Sublime Text docs: ST4 subl, ST3 subl or ST2 subl\nIf you do make any edits to this file once you have closed it, you need to run the command:\n source ~/.bash_profile \n\nto compile your newly applied edits. If you see any errors after sourcing your file get them fixed before moving to the final step.\n\nCreate a symbolic link to Sublime Text:\nNow in your chosen path (I used /usr/local/bin) you now enter the following command:\n ln -s /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl /usr/local/bin/subl\n\nThe /Applications/Sublime\\ Text.app/Contents/SharedSupport/bin/subl being EXACTLY the same location as what you entered and verified as working in STEP 1 above. The /usr/local/bin/subl being the location of where you want the symbolic link to be located - needs to be one of your PATH locations from STEP 2 above.\nNow when you navigate to a folder or file that you want to open in Sublime Text you now just enter subl followed by the name of the file or . to open the current working directory."
  },
  {
    "question": "Unable to show a Git tree in terminal",
    "answer": "How can you get the tree-like view of commits in terminal?\n\ngit log --graph --oneline --all\n\n\nis a good start.\n\nYou may get some strange letters. They are ASCII codes for colors and structure. To solve this problem add the following to your .bashrc:\n\nexport LESS=\"-R\"\n\n\nsuch that you do not need use Tig's ASCII filter by\n\ngit log --graph --pretty=oneline --abbrev-commit | tig   // Masi needed this \n\n\nThe article text-based graph from Git-ready contains other options:\n\ngit log --graph --pretty=oneline --abbrev-commit\n\n\n\n\nRegarding the article you mention, I would go with Pod's answer: ad-hoc hand-made output.\n\n\n\nJakub Narębski mentions in the comments tig, a ncurses-based text-mode interface for git. See their releases.\nIt added a --graph option back in 2007."
  },
  {
    "question": "OS X Terminal Colors",
    "answer": "Here is a solution I've found to enable the global\nterminal colors.\n\nEdit your .bash_profile (since OS X 10.8) — or (for 10.7 and earlier): .profile or .bashrc or /etc/profile (depending on availability) — in your home directory and add following code:\n\nexport CLICOLOR=1\nexport LSCOLORS=GxFxCxDxBxegedabagaced\n\n\nCLICOLOR=1 simply enables coloring of your terminal.\n\nLSCOLORS=... specifies how to color specific items. \n\nAfter editing .bash_profile, start a Terminal and force the changes to take place by executing:\n\nsource ~/.bash_profile\n\nThen go to Terminal > Preferences, click on the Profiles tab and then the Text subtab and check Display ANSI Colors.\n\nVerified on Sierra (May 2017)."
  },
  {
    "question": "Concatenate multiple files but include filename as section headers",
    "answer": "Was looking for the same thing, and found this to suggest:\n\ntail -n +1 file1.txt file2.txt file3.txt\n\n\nOutput:\n\n==> file1.txt <==\n<contents of file1.txt>\n\n==> file2.txt <==\n<contents of file2.txt>\n\n==> file3.txt <==\n<contents of file3.txt>\n\n\nIf there is only a single file then the header will not be printed. If using GNU utils, you can use -v to always print a header."
  },
  {
    "question": "Keep SSH session alive",
    "answer": "The ssh daemon (sshd), which runs server-side, closes the connection from the server-side if the client goes silent (i.e., does not send information). To prevent connection loss, instruct the ssh client to send a sign-of-life signal to the server once in a while.\n\nThe configuration for this is in the file $HOME/.ssh/config, create the file if it does not exist (the config file must not be world-readable, so run chmod 600 ~/.ssh/config after creating the file). To send the signal every e.g. four minutes (240 seconds) to the remote host, put the following in that configuration file:\n\nHost remotehost\n    HostName remotehost.com\n    ServerAliveInterval 240\n\n\nTo enable sending a keep-alive signal for all hosts, place the following contents in the configuration file:\n\nHost *\n    ServerAliveInterval 240"
  },
  {
    "question": "Change the default terminal in Visual Studio Code",
    "answer": "You can also select your default terminal by pressing F1 in Visual Studio Code and typing/selecting Terminal: Select Default Profile (or Terminal: Select Default Shell in older Visual Studio Code versions).\n\nOlder:"
  },
  {
    "question": "How can I turn off &quot;scrolling the history&quot; in iTerm2",
    "answer": "A few terminals, including iTerm2, have a feature where they change the behavior of the wheel mouse when a full-screen program such as vi, or screen or tmux is running.  This happens when those programs use the alternate screen, to provide a useful function.  Normally, when using the alternate screen in iTerm2, the wheel mouse acts like the scrollbar, scrolling the entire screen up/down.  But when this feature is enabled, iTerm2 sends cursor up/down keys, making your command-history change.\n\nAs suggested in another comment, select the Preferences menu:\n\n\n\nand in that, select the Advanced tab.  Scroll down to the Mouse section,\n\n\n\nand toggle the entry for\n\nScroll wheel sends arrow keys when in alternate screen mode\n\nfrom Yes to No.  You will have to restart iTerm2 for the change to take effect.  (With iTerm2 v3.1.5 changes take effect without restarting.)"
  },
  {
    "question": "How to exit a &#39;git status&#39; list in a terminal?",
    "answer": "I have to guess here, but git is probably running its output into your $PAGER program, likely less or more. In either case, typing q should get you out."
  },
  {
    "question": "Clear a terminal screen for real",
    "answer": "Use the following command to do a clear screen instead of merely adding new lines ...\nprintf \"\\033c\"\n\nyes that's a 'printf' on the bash prompt.\nYou will probably want to define an alias though...\nalias cls='printf \"\\033c\"'\n\nExplanation\n\\033 == \\x1B == 27 == ESC\n\nSo this becomes <ESC>c which is the VT100 escape code for resetting the terminal. Here is some more information on terminal escape codes.\nEdit\nHere are a few other ways of doing it...\nprintf \"\\ec\" #\\e is ESC in bash\necho -en \"\\ec\" #thanks @Jonathon Reinhart.\n# -e    Enable interpretation of of backslash escapes\n# -n    Do not output a new line\n\nKDE\nThe above does not work on the KDE console (called Konsole) but there is hope! Use the following sequence of commands to clear the screen and the scroll-back buffer...\nclear && echo -en \"\\e[3J\"\n\nOr perhaps use the following alias on KDE...\nalias cls='clear && echo -en \"\\e[3J\"'\n\nI got the scroll-back clearing command from here."
  },
  {
    "question": "How to remove files and directories quickly via terminal (bash shell)",
    "answer": "rm -rf some_dir\n\n\n-r \"recursive\"\n-f \"force\" (suppress confirmation messages)\n\nBe careful!"
  },
  {
    "question": "How do I find the width &amp; height of a terminal window?",
    "answer": "tput cols tells you the number of columns.\ntput lines tells you the number of rows."
  },
  {
    "question": "After installing Homebrew I get `zsh: command not found: brew`",
    "answer": "I had a similar issue on macOS Big Sur (11.0.1). In my case homebrew was saved in /opt/homebrew/, and not in /usr/local/....\nSo I added\nexport PATH=/opt/homebrew/bin:$PATH\nto .zshrc file in my home directory, and the ZSH shell was able to find the brew command."
  }
]